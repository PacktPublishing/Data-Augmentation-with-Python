{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duchaba/Data-Augmentation-with-Python/blob/main/data_augmentation_with_python_chapter_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DlWAB8G4ijz"
      },
      "source": [
        "## ðŸŒ» Welcome to Chapter 9, Tabular Data Augmentation\n",
        "\n",
        "---\n",
        "\n",
        "I am glad to see you using this Python Notebook. ðŸ¶\n",
        "\n",
        "The Python Notebook is an integral part of the book. You can add new â€œcode cellsâ€ to extend the functions, add your data, and explore new possibilities, such as downloading additional real-world datasets from the Kaggle website and coding the **Fun challenges**. Furthermore, the book has **Fun facts**, in-depth discussion about augmentation techniques, and Pluto, an imaginary Siberian Huskey coding companion. Together they will guide you every steps of the way. \n",
        "\n",
        "Pluto encourages you to copy or save a copy of this Python Notebook to your local space and add the â€œtext cellsâ€ to keep your notes. In other words, read the book and copy the relevant concept to this Python Notebookâ€™s text-cells. Thus, you can have the explanation, note, original code, your code, and any crazy future ideas in one place.  \n",
        "\n",
        "\n",
        "ðŸ’— I hope you enjoy reading the book and hacking code as much as I enjoy writing it. \n",
        "\n",
        "\n",
        "## ðŸŒŸ Amazon Book\n",
        "\n",
        "---\n",
        "\n",
        "- The book is available on the Amazon Book website: \n",
        "  - https://www.amazon.com/dp/1803246456\n",
        "\n",
        "  - Author: Duc Haba\n",
        "  - Published: 2023\n",
        "  - Page count: 390+\n",
        "\n",
        "\n",
        "- The original Python Notebook is on: \n",
        "  - https://github.com/PacktPublishing/Data-Augmentation-with-Python/blob/main/Chapter_9/data_augmentation_with_python_chapter_9.ipynb \n",
        "\n",
        "- ðŸš€ Click on the blue \"Open in Colab\" button at the top of this page to begin hacking.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ8-JIXv6jmV"
      },
      "source": [
        "# ðŸ˜€ Excerpt from Chapter 9, Tabular Data Augmentation \n",
        "\n",
        "---\n",
        "\n",
        "> In case you havenâ€™t bought the book. Here is an teaser from the first page of Chapter 9.\n",
        "\n",
        "---\n",
        "\n",
        "Tabular augmentation supplements tabular data with additional information to make it more useful for predictive analytics. Database, spreadsheet, and table data are examples of tabular data. It involves transforming otherwise insufficient datasets into robust inputs for ML. Tabular augmentation can help turn unstructured data into structured data and can also assist in combining multiple data sources into a single dataset. It is an essential step in data pre-processing for increasing AI predictive accuracy.\n",
        "\n",
        "The idea of tabular augmentation is to include additional information to a given dataset that can then be used to generate valuable insights. These datasets can come from various sources, such as customer feedback, social media posts, and IoT device logs. Tabular augmentation can add new information columns to the dataset by enriching the existing columns with more informative tags. It increases the completeness of the dataset and provides more accurate insights.\n",
        "\n",
        "Tabular augmentation is an important method to consider when pre-processing and generating insights from data. It provides a way to work with incomplete and unstructured datasets by organizing and enriching them for improved accuracy and speed. By implementing tabular augmentation, you can better unlock the value of real-world datasets and make better-informed decisions.\n",
        "\n",
        "Tabular augmentation is a young field for data scientists. It is contrary to using analytics for reporting, summarizing, or forecasting. In analytics, altering or adding data to skew the results to a preconceived desired outcome is unethical. In data augmentation, the purpose is to derive new data from an existing dataset. The two goals might be incongruent, but they are not. DL is an entirely different technique from traditional analytics. One is based on a neural network algorithm, while the other is based on statistical analysis and data relationships.\n",
        "\n",
        "The salient point is that even though you might introduce synthetic data into the datasets, it is an acceptable practice. The Synthesizing Tabular Data using Generative Adversarial Networks paper, by Lei Xu and Kalyan Veeramachaneni, published in the arXiv Forum in November 2018, supports this proposition.\n",
        "\n",
        "This chapter focuses on describing concepts. It has a few practical coding examples using the Python Notebook. One main reason for this is that there are only a few tabular augmentation open source libraries available. You will spend most of the coding time plotting various graphs to inspire further insight from the datasets.\n",
        "\n",
        "Before continuing, letâ€™s take a sneak peek at a real-world tabular dataset. Later, Pluto will explain in detail how to write Python code for the following:\n",
        "\n",
        "> ...SKIP...IMAGE...\n",
        "\n",
        "Figure 9.1 â€“ Bank Account Fraud Dataset Suite (NeurIPS 2022)\n",
        "\n",
        "One challenge in augmenting tabular data is that no fixed methods work universally, such as flipping images, injecting misspelled words, or time-stretching audio files. You will learn that the dataset dictates which augmentation techniques are safe or in a safe range. It is essential to thoroughly review the tabular dataset before augmenting it.\n",
        "\n",
        "---\n",
        "\n",
        "Fun fact\n",
        "\n",
        "---\n",
        "\n",
        "Deep neural networks (DNNs) excel at predicting future stock values and tabular data, based on the scholarly paper Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies, by Eunsuk Chong, Chulwoo Han, and Frank C. Park. It was published by Elsevier, Expert Systems with Applications, Volume 83, on 15 October 2017.\n",
        "\n",
        "---\n",
        "\n",
        "Tabular augmentation is an approach to augmenting a tabular dataset with synthetic data. It involves adding new columns to a tabular dataset with features from the derived calculation. You will spend the majority of the time in Python code visualizing the real-world tabular dataset with exotics plots. In this chapter, we will cover the following topics:\n",
        "\n",
        "- Tabular augmentation libraries\n",
        "\n",
        "- Augmentation categories\n",
        "\n",
        "- Real-world tabular datasets\n",
        "\n",
        "- Exploring and visualizing tabular data\n",
        "\n",
        "- Transformation augmentation\n",
        "\n",
        "- Extraction augmentation\n",
        "\n",
        "Letâ€™s start with augmentation libraries.\n",
        "\n",
        "---\n",
        "\n",
        "ðŸŒ´ *end of excerpt from the book*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b52gSlp60SN"
      },
      "source": [
        "# GitHub Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oeDAu1u6zWf"
      },
      "outputs": [],
      "source": [
        "# git version should be 2.17.1 or higher\n",
        "!git --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9buwUR767Te"
      },
      "outputs": [],
      "source": [
        "url = 'https://github.com/PacktPublishing/Data-Augmentation-with-Python'\n",
        "!git clone {url}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOawA01L7Ok0"
      },
      "source": [
        "## Fetch file from URL (Optional)\n",
        "\n",
        "- Uncommend the below 2 code cells if you want to use URL and not Git Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsmQ7rgj67Ww"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# #\n",
        "# def fetch_file(url, dst):\n",
        "#   downloaded_obj = requests.get(url)\n",
        "#   with open(dst, \"wb\") as file:\n",
        "#     file.write(downloaded_obj.content)\n",
        "#   return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nKp0nxT67aH"
      },
      "outputs": [],
      "source": [
        "# url = ''\n",
        "# dst = 'pluto_chapter_1.py'\n",
        "# fetch_file(url,dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6462KTtr7cFQ"
      },
      "source": [
        "# Run Pluto\n",
        "\n",
        "- Instantiate up Pluto, aka. \"Pluto, wake up!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCGiTw16ZxVH"
      },
      "outputs": [],
      "source": [
        "# %% CARRY-OVER code install\n",
        "\n",
        "!pip install opendatasets --upgrade\n",
        "!pip install pyspellchecker "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3zbkOO86_WB"
      },
      "outputs": [],
      "source": [
        "#load and run the pluto chapter 1 Python code.\n",
        "pluto_file = 'Data-Augmentation-with-Python/pluto/pluto_chapter_2.py'\n",
        "%run {pluto_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhRR0JSf746h"
      },
      "source": [
        "## Verify Pluto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBIw7fiI6_Zy"
      },
      "outputs": [],
      "source": [
        "pluto.say_sys_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaURlsasaGuo"
      },
      "source": [
        "## (Optional) Export to .py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfx9Ai5Opyqp"
      },
      "outputs": [],
      "source": [
        "pluto_chapter_9 = 'Data-Augmentation-with-Python/pluto/pluto_chapter_9.py'\n",
        "!cp {pluto_file} {pluto_chapter_9}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ6ap39x8HyF"
      },
      "source": [
        "# âœ‹ Set up Kaggle username and app Key\n",
        "\n",
        "- Install the following libraries, and import it on the Notebook.\n",
        "- Follow by initialize Kaggle username, key and fetch methods.\n",
        "\n",
        "- STOP: Update your Kaggle access username or key first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf4Obdp-77CL"
      },
      "outputs": [],
      "source": [
        "# %%CARRY-OVER code \n",
        "\n",
        "# -------------------- : --------------------\n",
        "# READ ME\n",
        "# Chapter 2 begin:\n",
        "# Install the following libraries, and import it on the Notebook.\n",
        "# Follow by initialize Kaggle username, key and fetch methods.\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "# -------------------- : --------------------\n",
        "\n",
        "!pip install opendatasets --upgrade\n",
        "import opendatasets\n",
        "print(\"\\nrequired version 0.1.22 or higher: \", opendatasets.__version__)\n",
        "\n",
        "!pip install pyspellchecker \n",
        "import spellchecker\n",
        "print(\"\\nRequired version 0.7+\", spellchecker.__version__)\n",
        "\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "pluto.remember_kaggle_access_keys(\"YOUR_KAGGLE_USERNAME\", \"YOUR_KAGGLE_KEY\")\n",
        "pluto._write_kaggle_credit()\n",
        "import kaggle\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_comp_data(self,cname):\n",
        "  #self._write_kaggle_credit()  # need to run only once.\n",
        "  path = pathlib.Path(cname)\n",
        "  kaggle.api.competition_download_cli(str(path))\n",
        "  zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
        "  return\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_dataset(self,url,dest=\"kaggle\"):\n",
        "  #self._write_kaggle_credit()    # need to run only once.\n",
        "  opendatasets.download(url,data_dir=dest)\n",
        "  return\n",
        "# -------------------- : --------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BfHiMQE8XWp"
      },
      "source": [
        "# Fetch Kaggle bank fraud data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TEFhsYs77Go"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "url = 'https://www.kaggle.com/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GHi9DnM77Kj"
      },
      "outputs": [],
      "source": [
        "f = '/content/kaggle/bank-account-fraud-dataset-neurips-2022/Base.csv'\n",
        "pluto.df_bank_data = pluto.fetch_df(f)\n",
        "pluto.df_bank_data.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data structure"
      ],
      "metadata": {
        "id": "hKHEkOx-E6Qu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZNbe6Nr8ILT"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25sDTv15oojo"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_data[['fraud_bool', \n",
        "  'proposed_credit_limit',\n",
        "  'customer_age', \n",
        "  'payment_type']].sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2wxKIUZ7-LY"
      },
      "outputs": [],
      "source": [
        "# Transpose for easier to read\n",
        "df = pluto.df_bank_data.describe()\n",
        "df = df.transpose()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_exUHUdZNhG"
      },
      "outputs": [],
      "source": [
        "df[['count','mean','std','min','max']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnVJVJsH8cBR"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_data.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First graph view"
      ],
      "metadata": {
        "id": "YFf6dcXwFJFr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04uBP5xibQ9Q"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "import matplotlib\n",
        "@add_method(PacktDataAug)\n",
        "def draw_tabular_histogram(self, df, title='Histogram',maxcolors=32):\n",
        "  canvas, pic = matplotlib.pyplot.subplots(1, 1, figsize=(12, 6))\n",
        "  comap = matplotlib.cm.get_cmap('rainbow', 256)\n",
        "  newcolors = comap(numpy.linspace(0, 1, maxcolors))\n",
        "  #newcolors = matplotlib.cm.cool(range(256))\n",
        "  df.plot.hist(ax=pic,color=newcolors)\n",
        "  #\n",
        "  pic.set_title(title,fontsize=20.0)\n",
        "  pic.legend(ncol=2, loc=\"upper right\")\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paR2cWXgbqqy"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_histogram(pluto.df_bank_data,\n",
        "  title='Bank Fraud data, 32 million points')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-cOpppjS8jT"
      },
      "source": [
        "# Categorical type \n",
        "\n",
        "- not continuous int or float numbers "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtPY3qg7_Wg2"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_data.payment_type.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HmEpen3SVb2"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_data.employment_status.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6GHc2SWSVfO"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_data.housing_status.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVVp_O_OSViP"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_data.source.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qFgq6ibSVlp"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_data.device_os.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DMelBLSORao"
      },
      "source": [
        "## Checksum, Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sau9I2seOQjY"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _fetch_token_index(self, val, xarr):\n",
        "  for i, x in enumerate(xarr):\n",
        "    if (val == x):\n",
        "      return i\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def add_token_index(self,df, df_colname):\n",
        "  for cname in df_colname:\n",
        "    tname = cname + \"_tokenize\"\n",
        "    arrname = numpy.array(df[cname].unique())\n",
        "    df[tname] = df[cname].apply(self._fetch_token_index, args=(arrname,))\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jfRiKvHRYj2"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_tokenize_data = pluto.df_bank_data.copy()\n",
        "pluto.add_token_index(pluto.df_bank_tokenize_data, \n",
        "  ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28FpPILtOQtL"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_tokenize_data[['payment_type', 'payment_type_tokenize']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6L5Pd3_OQwD"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_tokenize_data[['device_os', 'device_os_tokenize']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEjO0uyaOQ2D"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_tokenize_data = pluto.df_bank_tokenize_data.drop(\n",
        "  ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os'], axis=1)\n",
        "pluto.df_bank_tokenize_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3yPyuxmVxW_"
      },
      "source": [
        "### checksum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ8wqJszVAhC"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _fetch_checksum(self, df):\n",
        "  df['checksum'] = df.apply(\n",
        "  lambda x: numpy.mean(tuple(x)), axis=1)\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5wdbUdSWS5v"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "pluto._fetch_checksum(pluto.df_bank_tokenize_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGZP7Ek4fse1"
      },
      "source": [
        "## Subset of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pW1lMrBOcmRp"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_half_one_data = pluto.df_bank_tokenize_data.head(5000)\n",
        "pluto.df_bank_half_data = pluto.df_bank_tokenize_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBF9LEYofxds"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _drop_bank_columns(self, df):\n",
        "  df_out = df.drop(\n",
        "    ['name_email_similarity',\n",
        "    'prev_address_months_count',\n",
        "    'current_address_months_count',\n",
        "    'days_since_request',\n",
        "    'intended_balcon_amount',\n",
        "    'zip_count_4w',\n",
        "    'velocity_6h',\n",
        "    'velocity_24h',\n",
        "    'velocity_4w',\n",
        "    'bank_branch_count_8w',\n",
        "    'date_of_birth_distinct_emails_4w',\n",
        "    'phone_home_valid',\n",
        "    'bank_months_count',\n",
        "    'has_other_cards',\n",
        "    'foreign_request',\n",
        "    'session_length_in_minutes',\n",
        "    'keep_alive_session',\n",
        "    'device_distinct_emails_8w',\n",
        "    'housing_status_tokenize',\n",
        "    'source_tokenize',\n",
        "    'month',\n",
        "    'device_fraud_count',\n",
        "    'device_os_tokenize'],\n",
        "    axis=1)\n",
        "  return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZEsKJ7boRx3"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_half_data = pluto._drop_bank_columns(pluto.df_bank_half_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Dm5QfTbhMJh"
      },
      "outputs": [],
      "source": [
        "list(pluto.df_bank_half_data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specialize graphs"
      ],
      "metadata": {
        "id": "a9UJ3Tiq-IWY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMTo-1CwqylV"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "import seaborn\n",
        "@add_method(PacktDataAug)\n",
        "def draw_tabular_correlogram(self, df,title='', figsize=(12,10)):\n",
        "  canvas = matplotlib.pyplot.figure(figsize=figsize)\n",
        "  seaborn.heatmap(df.corr(), \n",
        "    xticklabels=df.corr().columns, \n",
        "    yticklabels=df.corr().columns, \n",
        "    cmap='viridis_r', \n",
        "    center=0, \n",
        "    annot=True)\n",
        "  #\n",
        "  matplotlib.pyplot.title(title, fontsize=20.0)\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXkMzXycsH1k"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_correlogram(pluto.df_bank_half_data,\n",
        "  title='Bank Fraud half Correlogram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajnT7_hNs_4i"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_correlogram(pluto.df_bank_tokenize_data,\n",
        "  title='Bank Fraud half Correlogram',\n",
        "  figsize=(22,24))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF_QwiYqD_cI"
      },
      "source": [
        "## heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDpZR9dEYDsJ"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def draw_tabular_heatmap(self, df, x='checksum', y='month'):\n",
        "  canvas, pic = matplotlib.pyplot.subplots(figsize=(12,6))\n",
        "  df.plot.hexbin(x=x, y=y, gridsize=20, ax=pic,cmap='Reds')\n",
        "  pic.set_title(f'Heatmap of {x} and {y}', fontsize=22.0)\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vMaxweSGE5d"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_heatmap(pluto.df_bank_tokenize_data, x='checksum', y='month')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCFCDiA0kZ-B"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_fraud_data = pluto.df_bank_tokenize_data[pluto.df_bank_tokenize_data.fraud_bool == 1]\n",
        "pluto.df_bank_fraud_data.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCv9eubDlEoJ"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89HTsuiD0nsx"
      },
      "outputs": [],
      "source": [
        "pluto.df_bank_fraud_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuCDHaXjEkyp"
      },
      "source": [
        "## (Optional) Seaborn heatmap, Swarmplot, and Tricolor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8JnTaK3MEqu"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Compute the correlation matrix\n",
        "corr = pluto.df_bank_fraud_data.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = numpy.triu(numpy.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "canvas, pic = matplotlib.pyplot.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = seaborn.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "seaborn.heatmap(corr, mask=mask, cmap='Set2', vmax=.3, center=0,\n",
        "  square=True, linewidths=.5, cbar_kws={\"shrink\": .5},\n",
        "  ax=pic)\n",
        "#\n",
        "pic.set_xticklabels([])\n",
        "pic.set_title(\"Seaborn Heatmap with Mask for Bank Fraud Data\",fontsize=20.0)\n",
        "canvas.tight_layout()\n",
        "pluto._drop_image(canvas)\n",
        "canvas.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_J7_NaOMExA"
      },
      "outputs": [],
      "source": [
        "# sns.jointplot(x=x, y=y, kind=\"hex\", color=\"#4CB391\")\n",
        "canvas, pic = matplotlib.pyplot.subplots(figsize=(12,6))\n",
        "seaborn.swarmplot(data=pluto.df_bank_tokenize_data.sample(2000),\n",
        "  x='fraud_bool', \n",
        "  y='checksum', \n",
        "  palette=\"Set2\",\n",
        "  ax=pic)\n",
        "pic.set_title(\"Swarmplot Bank data. sample 2,000 points\", fontsize=20.0)\n",
        "canvas.tight_layout()\n",
        "pluto._drop_image(canvas)\n",
        "canvas.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wS0yUQumg7BA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# plt.style.use('_mpl-gallery-nogrid')\n",
        "\n",
        "# make data:\n",
        "# numpy.random.seed(1)\n",
        "x = numpy.random.uniform(-3, 3, 256)\n",
        "y = numpy.random.uniform(-3, 3, 256)\n",
        "# x = pluto.df_world_tokenize_data.winning_team_tokenize\n",
        "# y = pluto.df_world_tokenize_data.losing_team_tokenize\n",
        "z = (1 - x/2 + x**5 + y**3) * numpy.exp(-x**2 - y**2)\n",
        "\n",
        "# plot:\n",
        "canvas, pic = matplotlib.pyplot.subplots(figsize=(12,5))\n",
        "\n",
        "# ax.plot(x, y, 'o', markersize=2, color='grey')\n",
        "pic.tripcolor(x, y, z, cmap='BrBG')\n",
        "\n",
        "# ax.set(xlim=(-3, 3), ylim=(-3, 3))\n",
        "pic.set_title(\"Tripcolor plot over X, Y, and Z\", fontsize=20.0)\n",
        "canvas.tight_layout()\n",
        "pluto._drop_image(canvas)\n",
        "canvas.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egL60f3BhEA_"
      },
      "source": [
        "## (Optional) Load Varient 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mquZNaO1ME3R"
      },
      "outputs": [],
      "source": [
        "# remove white space in directory and filename\n",
        "# run this until no error/output\n",
        "f = 'kaggle/bank-account-fraud-dataset-neurips-2022'\n",
        "#!find {f} -name \"* *\" -type d | rename 's/ /_/g'\n",
        "!find {f} -name \"* *\" -type f | rename 's/ /_/g'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUMqc7EQhDTu"
      },
      "outputs": [],
      "source": [
        "f = '/content/kaggle/bank-account-fraud-dataset-neurips-2022/Variant_I.csv'\n",
        "pluto.df_bank_v1_data = pluto.fetch_df(f)\n",
        "pluto.df_bank_v1_data.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X7K1aV9r36_"
      },
      "source": [
        "# World Series Baseball Television Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCHc3iRer3N_"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "f = 'https://www.kaggle.com/datasets/mattop/world-series-baseball-television-ratings'\n",
        "pluto.fetch_kaggle_dataset(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfw6FXBwr3Rt"
      },
      "outputs": [],
      "source": [
        "f = '/content/kaggle/world-series-baseball-television-ratings/world-series-ratings.csv'\n",
        "pluto.df_world_data = pluto.fetch_df(f)\n",
        "pluto.df_world_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYOI8M5elcPB"
      },
      "outputs": [],
      "source": [
        "pluto.df_world_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsoQN3rklcSc"
      },
      "outputs": [],
      "source": [
        "pluto.df_world_data.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtnAucdZwPl9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "pluto.df_world_tokenize_data = pluto.df_world_data.copy()\n",
        "pluto.df_world_tokenize_data = pluto.df_world_tokenize_data.fillna(0)\n",
        "pluto.add_token_index(pluto.df_world_tokenize_data, \n",
        "  ['network', 'winning_team', 'losing_team'])\n",
        "pluto.df_world_tokenize_data = pluto.df_world_tokenize_data.drop(\n",
        "  ['network', 'winning_team', 'losing_team'], \n",
        "  axis=1)\n",
        "pluto._fetch_checksum(pluto.df_world_tokenize_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYyDFaAHhr8T"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_histogram(pluto.df_world_data,\n",
        "  title='World Series Baseball',\n",
        "  maxcolors=14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4qwdAVjwPpo"
      },
      "outputs": [],
      "source": [
        "pluto.df_world_tokenize_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV4CLei5hv_K"
      },
      "outputs": [],
      "source": [
        "!pip install joypy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm_YV5N0R_xn"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_correlogram(pluto.df_world_tokenize_data,\n",
        "  title='World Series Baseball Correlogram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrtEeMDZbraK"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "import joypy\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def draw_tabular_joyplot(self, df, x=[], y='network', t='',legloc='upper left'):\n",
        "  canvas, pics = joypy.joyplot(df, \n",
        "    column=x, \n",
        "    by=y, \n",
        "    ylim='own', figsize=(12,6),\n",
        "    overlap=1)\n",
        "\n",
        "  # Decoration\n",
        "  matplotlib.pyplot.title(t, fontsize=22)\n",
        "  pics[0].legend(ncol=2, loc=legloc)\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_E438HhcXOL"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_joyplot(pluto.df_world_data, \n",
        "  x=['game_1_audience', 'game_2_audience', 'game_3_audience',\n",
        "     'game_4_audience', 'game_5_audience', 'game_6_audience', \n",
        "     'game_7_audience'],\n",
        "  y='network',\n",
        "  t='World series baseball audience')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4JGDY8Kfj73"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_joyplot(pluto.df_world_tokenize_data, \n",
        "  x=['checksum', 'average_audience'],\n",
        "  y='network_tokenize',\n",
        "  t='World series baseball, checksum and average auidence',\n",
        "  legloc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JggxT2OiwQEg"
      },
      "outputs": [],
      "source": [
        "! pip install pywaffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqj3KX4JklL_"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "import pywaffle\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def draw_tabular_waffle(self, df_orig, col='winning_team', \n",
        "  title='',legloc='lower center', anchor=(0.5, -0.5)):\n",
        "  df = df_orig.groupby(col).size().reset_index(name='counts')\n",
        "  cat = df.shape[0]\n",
        "  colors = [matplotlib.pyplot.cm.nipy_spectral(i/float(cat)) for i in range(cat)]\n",
        "\n",
        "  # Draw Plot and Decorate\n",
        "  canvas = matplotlib.pyplot.figure(\n",
        "    FigureClass=pywaffle.Waffle,\n",
        "    # plots={\n",
        "    #   '111': {\n",
        "    #     # 'values': df['counts'],\n",
        "    #     'labels': [\"{0} ({1})\".format(n[0], n[1]) for n in df[[col, 'counts']].itertuples()],\n",
        "    #     'legend': {'loc': legloc, 'fontsize': 11, 'ncol': 4, 'bbox_to_anchor':anchor},\n",
        "    #     'title': {'label': title, 'loc': 'center', 'fontsize':20.0}},},\n",
        "      rows=4,\n",
        "      values=df['counts'],\n",
        "      colors=colors,\n",
        "      figsize=(10, 8))\n",
        "  #\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjnYipxKm13d"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_waffle(pluto.df_world_data, \n",
        "  col='winning_team',\n",
        "  title='World Series Baseball Winning Team')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIKcHR3arDop"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_waffle(pluto.df_world_data, \n",
        "  col='losing_team',\n",
        "  title='World Series Baseball Losing Team')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DiLP4bOsvv5"
      },
      "outputs": [],
      "source": [
        "\n",
        "pluto.draw_tabular_waffle(pluto.df_world_data, \n",
        "  col='network',\n",
        "  title='World Series Baseball Network',\n",
        "  anchor=(0.5, -0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtbCwJZQmE7l"
      },
      "source": [
        "# Transformation Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ‹ STOP\n",
        "\n",
        "- The below install pystan and fbprophet takes upto 11 minutes.\n",
        "- **Warning: The library is beta release and may be unstable."
      ],
      "metadata": {
        "id": "5M0w44wOAS8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!pip install pystan==2.18.0.0\n",
        "!pip install fbprophet\n",
        "!pip install deltapy"
      ],
      "metadata": {
        "id": "8fjxMkxln_5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5w_-b9Rj94U"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "!pip install pykalman\n",
        "!pip install tsaug\n",
        "!pip install ta\n",
        "!pip install tsaug\n",
        "!pip install pandasvault\n",
        "!pip install gplearn\n",
        "!pip install ta\n",
        "!pip install seasonal\n",
        "!pip install pandasvault"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deltapy"
      ],
      "metadata": {
        "id": "9DnO-6rIryLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robust Scaler"
      ],
      "metadata": {
        "id": "zWfCCt3HA--P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "import matplotlib\n",
        "@add_method(PacktDataAug)\n",
        "def augment_tabular_robust_scaler(self, df):\n",
        "  return deltapy.transform.robust_scaler(df.copy(), drop=[\"checksum\"])"
      ],
      "metadata": {
        "id": "YMXny5kxBV01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_out = pluto.augment_tabular_robust_scaler(\n",
        "  pluto.df_world_tokenize_data) "
      ],
      "metadata": {
        "id": "hO7EYz7JBZDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1ihXT-lIMjr"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_joyplot(df_out, \n",
        "  x=['game_1_audience', 'game_2_audience', 'game_3_audience',\n",
        "     'game_4_audience', 'game_5_audience', 'game_6_audience', \n",
        "     'game_7_audience'],\n",
        "  y='network_tokenize',\n",
        "  t='World series baseball audience')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2DqcZrvIMnr"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_waffle(df_out, \n",
        "  col='network_tokenize',\n",
        "  title='World Series Baseball Network',\n",
        "  anchor=(0.5, -0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HORRSZmBXvgv"
      },
      "source": [
        "## Standard scaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def augment_tabular_standard_scaler(self, df):\n",
        "  return deltapy.transform.standard_scaler(df.copy(), drop=[\"checksum\"])"
      ],
      "metadata": {
        "id": "R6ByOjoQCcLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_out = pluto.augment_tabular_standard_scaler( \n",
        "  pluto.df_world_tokenize_data) "
      ],
      "metadata": {
        "id": "8oRIIsu4CcRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si-8FsnpIMvv"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_joyplot(df_out, \n",
        "  x=['game_1_audience', 'game_2_audience', 'game_3_audience',\n",
        "     'game_4_audience', 'game_5_audience', 'game_6_audience', \n",
        "     'game_7_audience'],\n",
        "  y='network_tokenize',\n",
        "  t='World series baseball audience',\n",
        "  legloc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qlm6ROwRIMyw"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_waffle(df_out, \n",
        "  col='network_tokenize',\n",
        "  title='World Series Baseball Network',\n",
        "  anchor=(0.5, -0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIqE7wZzZ-wy"
      },
      "source": [
        "## Capping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def augment_tabular_capping(self, df):\n",
        "  x, y = deltapy.transform.outlier_detect(df, \"checksum\")\n",
        "  return deltapy.transform.windsorization(df.copy(),\"checksum\",y,strategy='both')"
      ],
      "metadata": {
        "id": "n0ZIsQ5NDIUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_out = pluto.augment_tabular_capping( \n",
        "  pluto.df_bank_tokenize_data) "
      ],
      "metadata": {
        "id": "WxKlHQweDIYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcDuffatYZNT"
      },
      "outputs": [],
      "source": [
        "df_out = pluto._drop_bank_columns(df_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NreE0L9oYZQs"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_correlogram(df_out, \n",
        "  title='Bank Fraud Capping Transformation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeHbsuaoZWEl"
      },
      "source": [
        "# Interaction augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsDGS4bCZy85"
      },
      "source": [
        "## Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def augment_tabular_regression(self, df):\n",
        "  return deltapy.interact.lowess(\n",
        "    df.copy(), \n",
        "    [\"winning_team_tokenize\",\"losing_team_tokenize\"], \n",
        "    pluto.df_world_tokenize_data[\"checksum\"], \n",
        "    f=0.25, iter=3)"
      ],
      "metadata": {
        "id": "DHODY1auE7Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_out = pluto.augment_tabular_regression( \n",
        "  pluto.df_world_tokenize_data) "
      ],
      "metadata": {
        "id": "ooG3q2JvE7KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqOeFV2eZfuF"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_joyplot(df_out, \n",
        "  x=['game_1_audience', 'game_2_audience', 'game_3_audience',\n",
        "     'game_4_audience', 'game_5_audience', 'game_6_audience', \n",
        "     'game_7_audience'],\n",
        "  y='network_tokenize',\n",
        "  t='World series baseball audience: Regression',\n",
        "  legloc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A90BWwWZfyK"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_waffle(df_out, \n",
        "  col='network_tokenize',\n",
        "  title='World Series Baseball Network: Regression',\n",
        "  anchor=(0.5, -0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xQAQ3HjOZWA"
      },
      "outputs": [],
      "source": [
        "pluto.draw_tabular_correlogram(df_out, \n",
        "  title='World Series Baseball: Regression')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6-1hGejeYhT"
      },
      "source": [
        "## Operator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_9}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def augment_tabular_operator(self, df):\n",
        "  return deltapy.interact.muldiv(\n",
        "    df.copy(), \n",
        "    [\"credit_risk_score\",\"proposed_credit_limit\"])"
      ],
      "metadata": {
        "id": "yaRVMg0VFukW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_out = pluto.augment_tabular_operator( \n",
        "  pluto.df_bank_tokenize_data) "
      ],
      "metadata": {
        "id": "zzOEv7JhFun5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKL26_4iZgJl"
      },
      "outputs": [],
      "source": [
        "df_out = pluto._drop_bank_columns(df_out)\n",
        "pluto.draw_tabular_correlogram(df_out, \n",
        "  title='Bank Fraud Operator Interaction')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('End of chapter 9')"
      ],
      "metadata": {
        "id": "QA7rVkX2w-Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEj7fgaIN9_S"
      },
      "source": [
        "# Push up all changes (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHXRf21BT9N8"
      },
      "source": [
        "- username: duchaba\n",
        "\n",
        "- password: [use the token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSXJKJFlOEeE"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# f = 'Data-Augmentation-with-Python'\n",
        "# os.chdir(f)\n",
        "# !git add -A\n",
        "# !git config --global user.email \"duc.haba@gmail.com\"\n",
        "# !git config --global user.name \"duchaba\"\n",
        "# !git commit -m \"end of session\"\n",
        "# # do the git push in the xterm console\n",
        "# #!git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMJgBjC1Px5A"
      },
      "outputs": [],
      "source": [
        "# %%script false --no-raise-error  #temporary stop execute for export file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzO7lDYDWeLz"
      },
      "source": [
        "# Summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2iUPf3EWePd"
      },
      "source": [
        "Every chaper will begin with same base class \"PacktDataAug\".\n",
        "\n",
        "âœ‹ FAIR WARNING:\n",
        "\n",
        "- The coding uses long and complete function path name.\n",
        "\n",
        "- Pluto wrote the code for easy to understand and not for compactness, fast execution, nor cleaverness.\n",
        "\n",
        "- Use Xterm to debug cloud server\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXRG3KaeWbGx"
      },
      "outputs": [],
      "source": [
        "# !pip install colab-xterm\n",
        "# %load_ext colabxterm\n",
        "# %xterm"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}