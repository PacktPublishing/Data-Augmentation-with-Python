{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duchaba/Data-Augmentation-with-Python/blob/main/data_augmentation_with_python_chapter_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation with Python, Chapter 6"
      ],
      "metadata": {
        "id": "SIt9Tm6eXARu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŒ» Welcome to Chapter 6, \"Text Augmentation with Machine Learning\"\n",
        "\n",
        "In this chapter, you will learn:\n",
        "\n",
        "- Machine Learning models \n",
        "\n",
        "- Word augmenting \n",
        "\n",
        "- Sentence augmenting \n",
        "\n",
        "- Real-world NLP datasets \n",
        "\n",
        "- Reinforce learning through Python code "
      ],
      "metadata": {
        "id": "1DlWAB8G4ijz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Notebook"
      ],
      "metadata": {
        "id": "ZZ8-JIXv6jmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This Notebook original link is: \n",
        "  - https://github.com/PacktPublishing/Data-Augmentation-with-Python/blob/main/data_augmentation_with_python_chapter_6.ipynb"
      ],
      "metadata": {
        "id": "hZhktqct6ZTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GitHub Clone"
      ],
      "metadata": {
        "id": "4b52gSlp60SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==4.2.0\n",
        "import gensim\n",
        "print(gensim.__version__)\n",
        "# version4.2.0"
      ],
      "metadata": {
        "id": "XIngCjpIiy9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# git version should be 2.17.1 or higher\n",
        "!git --version"
      ],
      "metadata": {
        "id": "6oeDAu1u6zWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://github.com/PacktPublishing/Data-Augmentation-with-Python'\n",
        "url = 'https://github.com/duchaba/Data-Augmentation-with-Python'\n",
        "!git clone {url}"
      ],
      "metadata": {
        "id": "J9buwUR767Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch file from URL (Optional)\n",
        "\n",
        "- Uncommend the below 2 code cells if you want to use URL and not Git Clone"
      ],
      "metadata": {
        "id": "lOawA01L7Ok0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# #\n",
        "# def fetch_file(url, dst):\n",
        "#   downloaded_obj = requests.get(url)\n",
        "#   with open(dst, \"wb\") as file:\n",
        "#     file.write(downloaded_obj.content)\n",
        "#   return"
      ],
      "metadata": {
        "id": "HsmQ7rgj67Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# url = ''\n",
        "# dst = 'pluto_chapter_1.py'\n",
        "# fetch_file(url,dst)"
      ],
      "metadata": {
        "id": "_nKp0nxT67aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Pluto\n",
        "\n",
        "- Instantiate up Pluto, aka. \"Pluto, wake up!\""
      ],
      "metadata": {
        "id": "6462KTtr7cFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% CARRY-OVER code install\n",
        "\n",
        "!pip install opendatasets --upgrade\n",
        "!pip install pyspellchecker \n",
        "!pip install missingno\n",
        "!pip install nltk\n",
        "!pip install wordcloud\n",
        "!pip install filter-profanity\n",
        "!pip install nlpaug"
      ],
      "metadata": {
        "id": "P10V_4JQ7DEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load and run the pluto chapter 1 Python code.\n",
        "pluto_file = 'Data-Augmentation-with-Python/pluto/pluto_chapter_5.py'\n",
        "%run {pluto_file}"
      ],
      "metadata": {
        "id": "u3zbkOO86_WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify Pluto"
      ],
      "metadata": {
        "id": "yhRR0JSf746h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.say_sys_info()"
      ],
      "metadata": {
        "id": "nBIw7fiI6_Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto_chapter_6 = 'Data-Augmentation-with-Python/pluto/pluto_chapter_6.py'\n",
        "!cp {pluto_file} {pluto_chapter_6}"
      ],
      "metadata": {
        "id": "Gfx9Ai5Opyqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âœ‹ Get Kaggle username and api key (Optional for this chapter)\n",
        "\n",
        "- Install the following libraries, and import it on the Notebook.\n",
        "- Follow by initialize Kaggle username, key and fetch methods.\n",
        "- STOP: Update your Kaggle access username or key first."
      ],
      "metadata": {
        "id": "kQ6ap39x8HyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- : --------------------\n",
        "# READ ME\n",
        "# Chapter 2 begin:\n",
        "# Install the following libraries, and import it on the Notebook.\n",
        "# Follow by initialize Kaggle username, key and fetch methods.\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "# -------------------- : --------------------\n",
        "\n",
        "!pip install opendatasets --upgrade\n",
        "import opendatasets\n",
        "print(\"\\nrequired version 0.1.22 or higher: \", opendatasets.__version__)\n",
        "\n",
        "!pip install pyspellchecker \n",
        "import spellchecker\n",
        "print(\"\\nRequired version 0.7+\", spellchecker.__version__)\n",
        "\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "pluto.remember_kaggle_access_keys(\"YOUR-USERNAME\", \"YOUR-KEY\")\n",
        "pluto._write_kaggle_credit()\n",
        "import kaggle\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_comp_data(self,cname):\n",
        "  #self._write_kaggle_credit()  # need to run only once.\n",
        "  path = pathlib.Path(cname)\n",
        "  kaggle.api.competition_download_cli(str(path))\n",
        "  zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
        "  return\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_dataset(self,url,dest=\"kaggle\"):\n",
        "  #self._write_kaggle_credit()    # need to run only once.\n",
        "  opendatasets.download(url,data_dir=dest)\n",
        "  return\n",
        "# -------------------- : --------------------\n"
      ],
      "metadata": {
        "id": "sf4Obdp-77CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch data from chapter 5"
      ],
      "metadata": {
        "id": "gFAQHzXjYvr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'Data-Augmentation-with-Python/pluto_data'\n",
        "!ls -la {f}"
      ],
      "metadata": {
        "id": "j-fk5IEEyfUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'Data-Augmentation-with-Python/pluto_data/netflix_data.csv'\n",
        "pluto.df_netflix_data = pluto.fetch_df(f,sep='~')"
      ],
      "metadata": {
        "id": "Asm98OsWXcvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'Data-Augmentation-with-Python/pluto_data/twitter_data.csv'\n",
        "pluto.df_twitter_data = pluto.fetch_df(f,sep='~')"
      ],
      "metadata": {
        "id": "5Xt1GrQXat_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_batch_text(pluto.df_netflix_data, cols=['title','description'])"
      ],
      "metadata": {
        "id": "Se_a_tFhXcyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_text_wordcloud(pluto.df_netflix_data.description, \n",
        "  xignore_words=wordcloud.STOPWORDS, \n",
        "  title='Word Cloud: Netflix Movie Review')"
      ],
      "metadata": {
        "id": "9quCB-ddXc1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_text_wordcloud(pluto.df_twitter_data.clean_tweet, \n",
        "  xignore_words=wordcloud.STOPWORDS, \n",
        "  title='Word Cloud: Twitter Tweets')"
      ],
      "metadata": {
        "id": "dWE1Gwb4Xc4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extened control text"
      ],
      "metadata": {
        "id": "YodrXsBjVH62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.orig_text = '''It was the best of times. It was the worst of times. It was the age of wisdom. It was the age of foolishness. It was the epoch of belief. It was the epoch of incredulity.'''\n",
        "pluto.orig_dickens_page = '''There were a king with a large jaw and a queen with a plain face, \n",
        "on the throne of England; there were a king with a large jaw and a queen with a fair face, on the throne of France. \n",
        "In both countries it was clearer than crystal to the lords of the State preserves of loaves and fishes, \n",
        "that things in general were settled for ever.\n",
        "It was the year of Our Lord one thousand seven hundred and seventy-five. \n",
        "Spiritual revelations were conceded to England at that favoured period, \n",
        "as at this. Mrs. Southcott had recently attained her five-and-twentieth blessed birthday, \n",
        "of whom a prophetic private in the Life Guards had heralded the sublime appearance \n",
        "by announcing that arrangements were made for the swallowing up of London and Westminster. \n",
        "Even the Cock-lane ghost had been laid only a round dozen of years, \n",
        "after rapping out its messages, \n",
        "as the spirits of this very year last past (supernaturally deficient in originality) rapped out theirs. \n",
        "Mere messages in the earthly order of events had lately come to the English Crown and People, \n",
        "from a congress of British subjects in America: which, strange to relate, \n",
        "have proved more important to the human race than any communications yet received through any of the chickens of the Cock-lane brood.'''\n",
        "\n",
        "pluto.orig_melville_page2 = '''Call me Ishmael. \n",
        "Some years agoâ€”never mind how long preciselyâ€”having little or no money in my purse, \n",
        "and nothing particular to interest me on shore, \n",
        "I thought I would sail about a little and see the watery part of the world. \n",
        "It is a way I have of driving off the spleen and regulating the circulation.'''\n",
        "\n",
        "pluto.orig_melville_page = '''Call me Ishmael. \n",
        "Some years agoâ€”never mind how long preciselyâ€”having little or no money in my purse, \n",
        "and nothing particular to interest me on shore, \n",
        "I thought I would sail about a little and see the watery part of the world. \n",
        "It is a way I have of driving off the spleen and regulating the circulation. \n",
        "Whenever I find myself growing grim about the mouth; whenever it is a damp, \n",
        "drizzly November in my soul; \n",
        "whenever I find myself involuntarily pausing before coffin warehouses, \n",
        "and bringing up the rear of every funeral I meet; \n",
        "and especially whenever my hypos get such an upper hand of me, \n",
        "that it requires a strong moral principle to prevent me from deliberately stepping into the street, \n",
        "and methodically knocking peopleâ€™s hats offâ€”then, \n",
        "I account it high time to get to sea as soon as I can. \n",
        "This is my substitute for pistol and ball. \n",
        "With a philosophical flourish Cato throws himself upon his sword; \n",
        "I quietly take to the ship. There is nothing surprising in this. \n",
        "If they but knew it, almost all men in their degree, some time or other, \n",
        "cherish very nearly the same feelings towards the ocean with me.'''\n",
        "\n",
        "#\n",
        "pluto.orig_carroll_page = '''Alice was beginning to get very tired of sitting by her sister on the bank, \n",
        "and of having nothing to do. \n",
        "Once or twice she had peeped into the book her sister was reading, \n",
        "but it had no pictures or conversations in it. \n",
        "â€œand what is the use of a book,â€ thought Alice â€œwithout pictures or conversations?â€\n",
        "So she was considering in her own mind. as well as she could, \n",
        "for the hot day made her feel very sleepy and stupid. \n",
        "whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, \n",
        "when suddenly a White Rabbit with pink eyes ran close by her.\n",
        "There was nothing so very remarkable in that; \n",
        "nor did Alice think it so very much out of the way to hear the Rabbit say to itself. \n",
        "â€œOh dear! Oh dear! I shall be late!â€ \n",
        "when she thought it over afterwards, \n",
        "it occurred to her that she ought to have wondered at this, \n",
        "but at the time it all seemed quite natural; \n",
        "but when the Rabbit actually took a watch out of its waistcoat-pocket, \n",
        "and looked at it, and then hurried on, Alice started to her feet, \n",
        "for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, \n",
        "or a watch to take out of it, \n",
        "and burning with curiosity, \n",
        "she ran across the field after it, \n",
        "and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.\n",
        "'''\n",
        "#\n",
        "pluto.orig_carroll_page2 = '''Alice was beginning to get very tired of sitting by her sister on the bank, \n",
        "and of having nothing to do. \n",
        "Once or twice she had peeped into the book her sister was reading, \n",
        "but it had no pictures or conversations in it.\n",
        "â€œand what is the use of a book,â€ thought Alice â€œwithout pictures or conversations?â€\n",
        "So she was considering in her own mind. as well as she could, \n",
        "for the hot day made her feel very sleepy and stupid. \n",
        "whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, \n",
        "when suddenly a White Rabbit with pink eyes ran close by her.'''\n",
        "#\n",
        "pluto.orig_self = '''Text augmentation with Machine Learning (ML) is an advanced technique. \n",
        "Ironically, Text augmentation aims to improve ML model accuracy, \n",
        "but we used a pre-trained ML model to create additional training NLP data. \n",
        "Itâ€™s a circular process. ML coding is not in this bookâ€™s scope, \n",
        "but understanding the difference between text augmentation using libraries and ML is beneficial.  \n",
        "Augmentation libraries, whether for image, text, or audio, \n",
        "follow the traditional programming methodologies with structure data, loops, \n",
        "and conditional statements in the algorithm. \n",
        "For example, from Chapter 5, the pseudo-code for implementing the method _print_aug_reserved() could be as follows:'''"
      ],
      "metadata": {
        "id": "LBiRho15VxTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@add_method(PacktDataAug)\n",
        "def _clean_text(self,x):\n",
        "  return (re.sub('[^A-Za-z0-9 .,!?#@]+', '', str(x)))"
      ],
      "metadata": {
        "id": "mgQDAvNGmlPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_netflix_data['description'] = pluto.df_netflix_data['description'].apply(pluto._clean_text)"
      ],
      "metadata": {
        "id": "LIeAnM3rmVB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO57mq6DOvZW"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls -la ../model/"
      ],
      "metadata": {
        "id": "oK-3H-GCRaRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nlpaug.util.file.download import DownloadUtil\n",
        "\n",
        "#DownloadUtil.download_word2vec(dest_dir='.') # word2vec\n",
        "DownloadUtil.download_glove(model_name='glove.6B', dest_dir='.') # GloVe\n",
        "DownloadUtil.download_fasttext(model_name='wiki-news-300d-1M', dest_dir='.') # fasttext model\n"
      ],
      "metadata": {
        "id": "jnSCgVH5WzxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  DownloadUtil.download_word2vec(dest_dir='.') # word2vec\n",
        "except Exception:\n",
        "  print('\\nIt happen frequently that this file can not be download due to too many access.')\n",
        "  print('When it failed, you can not use Word2Vec transformation/augmentation.')\n",
        "  print('You could download the file: GoogleNews-vectors-negative300.bin.gz')\n",
        "  print('From URL: https://drive.google.com/uc?export=download&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM \\n')"
      ],
      "metadata": {
        "id": "O4vC_3iKLAOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la gdrive/MyDrive/'Colab Notebooks'/data_not_sync"
      ],
      "metadata": {
        "id": "6Z5TihXmChfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp gdrive/MyDrive/'Colab Notebooks'/data_not_sync/GoogleNews-vectors-negative300.bin.gz ."
      ],
      "metadata": {
        "id": "4WA7JBy_Df40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "metadata": {
        "id": "0Yr5DqRzEkDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "metadata": {
        "id": "rYmT0Y7lEkGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @add_method(PacktDataAug)\n",
        "# def _print_aug_batch(self, df, aug_func, col_dest=\"description\",\n",
        "#   bsize=3, aug_name='Augmented', is_orig_control=True):\n",
        "#   col_name = [aug_name, 'Original']\n",
        "#   if (is_orig_control):\n",
        "#     aug = aug_func.augment(self.orig_text, n=1)\n",
        "#     data = [[aug[0], self.orig_text]]\n",
        "#     df_aug = pandas.DataFrame(data, columns=col_name)\n",
        "#   else:\n",
        "#     df_aug = pandas.DataFrame()\n",
        "#   orig = df[col_dest].sample(bsize)\n",
        "#   for tx in orig:\n",
        "#     aug = aug_func.augment(tx, n=1)\n",
        "#     data = [[aug[0], tx]]\n",
        "#     t = pandas.DataFrame(data, columns=col_name)\n",
        "#     df_aug = df_aug.append(t, ignore_index=True)\n",
        "#   #\n",
        "#   with pandas.option_context(\"display.max_colwidth\", None):\n",
        "#   #   df_aug.style.set_properties(**{\n",
        "#   #     'text-align': 'center',\n",
        "#   #     'white-space': 'pre-wrap',\n",
        "#   #   })\n",
        "#   # #\n",
        "#     display(df_aug.head(bsize+1))\n",
        "#   return\n"
      ],
      "metadata": {
        "id": "PvuCL666R6Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "import nlpaug\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ai_word2vec(self, df, \n",
        "  col_dest=\"description\",\n",
        "  action='insert',\n",
        "  model_type='word2vec',\n",
        "  model_path='GoogleNews-vectors-negative300.bin',\n",
        "  bsize=3, \n",
        "  aug_name='Augment',\n",
        "  is_orig_control=True):\n",
        "  aug_func = nlpaug.augmenter.word.WordEmbsAug(model_type=model_type,action=action,model_path=model_path)\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "IyIftW1iOqJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_word2vec(pluto.df_netflix_data,\n",
        "  col_dest='description',\n",
        "  action='insert',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "QJWmEr9CEvkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_word2vec(pluto.df_netflix_data,\n",
        "  col_dest='description',\n",
        "  action='insert',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "bpdpR53_OqMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_word2vec(pluto.df_twitter_data,col_dest='clean_tweet',action='insert',aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "BDMnyi0aOqPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## substitute"
      ],
      "metadata": {
        "id": "2lIhZzkeS3f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_word2vec(pluto.df_netflix_data,\n",
        "  col_dest='description',\n",
        "  action='substitute',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "rFi1CQDvS6Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_word2vec(pluto.df_twitter_data,\n",
        "  col_dest='clean_tweet',\n",
        "  action='substitute',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "QPJKjPGAS6Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_carroll_page], columns=['page'])\n",
        "pluto.print_aug_ai_word2vec(df_page,\n",
        "  col_dest='page',\n",
        "  action='substitute',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ],
      "metadata": {
        "id": "CH4qoUd9qkoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_christie_page], columns=['page'])\n",
        "pluto.print_aug_ai_word2vec(df_page,\n",
        "  col_dest='page',\n",
        "  action='substitute',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ],
      "metadata": {
        "id": "_R3uu_gJS6cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ert6W8iPOvZa"
      },
      "source": [
        "#BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0jvJUTYOvZa"
      },
      "source": [
        "- \n",
        "Insert word by contextual word embeddings (BERT, DistilBERT, RoBERTA or XLNet)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "gKfFXMpAsQ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "sTonbBjLGlvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpletransformers>=0.61.10\n",
        "import simpletransformers\n",
        "#print(simpletransformers.__version__)"
      ],
      "metadata": {
        "id": "hmfLVK_lG1ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk>=3.4.5\n",
        "!pip install gensim>=4.1.2"
      ],
      "metadata": {
        "id": "YfujVAx3G6Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "import nlpaug\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ai_bert(self, df, \n",
        "  col_dest=\"description\",\n",
        "  action='insert',\n",
        "  model_path='bert-base-uncased',\n",
        "  bsize=3, \n",
        "  aug_name='Augment',\n",
        "  is_orig_control=True):\n",
        "  aug_func = nlpaug.augmenter.word.ContextualWordEmbsAug(action=action,model_path=model_path)\n",
        "  #self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name,is_orig_control=is_orig_control)\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "-02N5CaMULnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_netflix_data,col_dest='description',\n",
        "  action='insert',aug_name='BERT Embedding Insert Augment')"
      ],
      "metadata": {
        "id": "dZdWtGcYT_jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pluto._print_aug_batch??"
      ],
      "metadata": {
        "id": "EE9kUedN9zkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  action='insert',aug_name='BERT Embedding Insert Augment')"
      ],
      "metadata": {
        "id": "EV7EV6OoT_tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### substitute"
      ],
      "metadata": {
        "id": "VeSjdgRSVLXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_netflix_data,col_dest='description',\n",
        "  action='substitute',aug_name='BERT Embedding Substitute Augment')"
      ],
      "metadata": {
        "id": "v6QDq9oiVTMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  action='substitute',aug_name='BERT Embedding Substitute Augment')"
      ],
      "metadata": {
        "id": "r8ZvWEySVTPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30ywh0jWOvZb"
      },
      "outputs": [],
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_dickens_page], columns=['page'])\n",
        "pluto.print_aug_ai_bert(df_page,\n",
        "  col_dest='page',\n",
        "  action='substitute',\n",
        "  aug_name='BERT Embedding Substitute Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgIO-PlOOvZc"
      },
      "outputs": [],
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_christie_page], columns=['page'])\n",
        "pluto.print_aug_ai_bert(df_page,\n",
        "  col_dest='page',\n",
        "  action='substitute',\n",
        "  aug_name='BERT Embedding Substitute Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa"
      ],
      "metadata": {
        "id": "u996W_0AVuXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_netflix_data,col_dest='description',\n",
        "  model_path='roberta-base',\n",
        "  action='insert',aug_name='Roberta Embedding Insert Augment')"
      ],
      "metadata": {
        "id": "QJEnGQC0V7Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  model_path='roberta-base',\n",
        "  action='insert',aug_name='Roberta Embedding Insert Augment')"
      ],
      "metadata": {
        "id": "eiQ68dyJV7Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### substitute"
      ],
      "metadata": {
        "id": "WPhvZqtAXStc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_netflix_data,col_dest='description',\n",
        "  model_path='roberta-base',\n",
        "  action='substitute',aug_name='Roberta Embedding Substitute Augment')"
      ],
      "metadata": {
        "id": "aSHAE7AaV7X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  model_path='roberta-base',\n",
        "  action='substitute',aug_name='Roberta Embedding Substitute Augment')"
      ],
      "metadata": {
        "id": "9W-_ZidFV7bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_dickens_page], columns=['page'])\n",
        "pluto.print_aug_ai_bert(df_page,\n",
        "  col_dest='page',\n",
        "  model_path='roberta-base',\n",
        "  action='substitute',\n",
        "  aug_name='Roberta Embedding Substitute Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ],
      "metadata": {
        "id": "twdvZPN2u4BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBf4gqwmOvZc"
      },
      "outputs": [],
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_christie_page], columns=['page'])\n",
        "pluto.print_aug_ai_bert(df_page,\n",
        "  col_dest='page',\n",
        "  model_path='roberta-base',\n",
        "  action='substitute',\n",
        "  aug_name='Roberta Embedding Substitute Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRtJ2z3_OvZj"
      },
      "source": [
        "# Back Translation "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "bfOwoGtJvkov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ai_back_translation(self, df, col_dest=\"description\",\n",
        "  from_model_name='facebook/wmt19-en-de', \n",
        "  to_model_name='facebook/wmt19-de-en',\n",
        "  bsize=3, aug_name='Augment',\n",
        "  is_orig_control=True):\n",
        "  aug_func = nlpaug.augmenter.word.BackTranslationAug(from_model_name=from_model_name,\n",
        "    to_model_name=to_model_name)\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "2peyD4nxXytF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_back_translation(pluto.df_netflix_data,col_dest='description',\n",
        "  from_model_name='facebook/wmt19-en-de', \n",
        "  to_model_name='facebook/wmt19-de-en',\n",
        "  aug_name='FaceBook Back Translation: English <-> German Augment')"
      ],
      "metadata": {
        "id": "TvQSRxQbXy8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/models"
      ],
      "metadata": {
        "id": "ya0J5nTybqc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_back_translation(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  from_model_name='facebook/wmt19-en-de', \n",
        "  to_model_name='facebook/wmt19-de-en',\n",
        "  aug_name='FaceBook Back Translation: English <-> German Augment')"
      ],
      "metadata": {
        "id": "gR1AitbqXzBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_back_translation(pluto.df_netflix_data,col_dest='description',\n",
        "  from_model_name='facebook/wmt19-en-de', \n",
        "  to_model_name='facebook/wmt19-de-en',\n",
        "  aug_name='FaceBook Back Translation: English <-> German Augment')"
      ],
      "metadata": {
        "id": "2InysGvoyBTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Russian"
      ],
      "metadata": {
        "id": "hbtGGU2__i3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_back_translation(pluto.df_netflix_data,col_dest='description',\n",
        "  from_model_name='facebook/wmt19-en-ru', \n",
        "  to_model_name='facebook/wmt19-ru-en',\n",
        "  aug_name='FaceBook Back Translation: English <-> Russian Augment')"
      ],
      "metadata": {
        "id": "T3GfAXRIaA4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_back_translation(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  from_model_name='facebook/wmt19-en-ru', \n",
        "  to_model_name='facebook/wmt19-ru-en',\n",
        "  aug_name='FaceBook Back Translation: English <-> Russian Augment')"
      ],
      "metadata": {
        "id": "9o8KPJN0aA8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fugumt-en-ja staka/fugumt-en-ja "
      ],
      "metadata": {
        "id": "m8eVtDKi7zcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pluto.print_aug_ai_back_translation(pluto.df_netflix_data,col_dest='description',\n",
        "#   from_model_name='sigmoid/mt5-en-ja', \n",
        "#   to_model_name='sigmoid/mt5-ja-en',\n",
        "#   aug_name='Sameer123 Back Translation: English <-> Japanese Augment')"
      ],
      "metadata": {
        "id": "RPXcl6AE8MA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pluto.print_aug_ai_back_translation(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "#   from_model_name='staka/fugumt-en-ja', \n",
        "#   to_model_name='staka/fugumt-en-ja',\n",
        "#   aug_name='Staka Back Translation: English <-> Japanese Augment')"
      ],
      "metadata": {
        "id": "vSJVMrlQ8MNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0KQKjM8z7zfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQSgixkIOvZj"
      },
      "outputs": [],
      "source": [
        "# import nlpaug.augmenter.word as naw\n",
        "\n",
        "# #text = 'The quick brown fox jumped over the lazy dog'\n",
        "# back_translation_aug = naw.BackTranslationAug(\n",
        "#     from_model_name='facebook/wmt19-en-de', \n",
        "#     to_model_name='facebook/wmt19-de-en'\n",
        "# )\n",
        "# back_translation_aug.augment(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSQxmMZmOvZj"
      },
      "outputs": [],
      "source": [
        "# %%script false --no-raise-error  #temporary stop execute for export file\n",
        "\n",
        "# # Load models from local path\n",
        "# import nlpaug.augmenter.word as naw\n",
        "\n",
        "# from_model_dir = os.path.join(os.environ[\"MODEL_DIR\"], 'word', 'fairseq', 'wmt19.en-de')\n",
        "# to_model_dir = os.path.join(os.environ[\"MODEL_DIR\"], 'word', 'fairseq', 'wmt19.de-en')\n",
        "\n",
        "# #text = 'The quick brown fox jumped over the lazy dog'\n",
        "# back_translation_aug = naw.BackTranslationAug(\n",
        "#     from_model_name=from_model_dir, from_model_checkpt='model1.pt',\n",
        "#     to_model_name=to_model_dir, to_model_checkpt='model1.pt', \n",
        "#     is_load_from_github=False)\n",
        "# back_translation_aug.augment(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH5ju1LAOvZl"
      },
      "source": [
        "# XLNet, Sentence Augmentation "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug.augmenter\n",
        "import nlpaug.augmenter.sentence\n",
        "text = 'It was a dark and stormy night.'\n",
        "aug = nlpaug.augmenter.sentence.ContextualWordEmbsForSentenceAug(\n",
        "      # model_path='gpt2'\n",
        "    # model_path='xlnet-base-cased',\n",
        "    model_path='distilgpt2', \n",
        "    # top_k=20\n",
        ")\n",
        "\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Text:\")\n",
        "for ii in range(5):\n",
        "    augmented_text = aug.augment(text)\n",
        "    print(augmented_text)"
      ],
      "metadata": {
        "id": "vzU26X95OQ_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece\n",
        "print(sentencepiece.__version__)"
      ],
      "metadata": {
        "id": "m-Yt9t4DORCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install sentencepiece\n",
        "# import sentencepiece"
      ],
      "metadata": {
        "id": "oAsSosGg9CV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nlpaug.augmenter.char as nac\n",
        "# import nlpaug.augmenter.word as naw\n",
        "# import nlpaug.augmenter.sentence as nas\n",
        "# import nlpaug.flow as nafc\n",
        "\n",
        "# from nlpaug.util import Action"
      ],
      "metadata": {
        "id": "FWHtsRj78s9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug\n",
        "import nlpaug.augmenter\n",
        "import nlpaug.augmenter.sentence"
      ],
      "metadata": {
        "id": "rfDGsttS82Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article = \"\"\"\n",
        "The history of natural language processing (NLP) generally started in the 1950s, although work can be \n",
        "found from earlier periods. In 1950, Alan Turing published an article titled \"Computing Machinery and \n",
        "Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence. \n",
        "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian \n",
        "sentences into English. The authors claimed that within three or five years, machine translation would\n",
        "be a solved problem. However, real progress was much slower, and after the ALPAC report in 1966, \n",
        "which found that ten-year-long research had failed to fulfill the expectations, funding for machine \n",
        "translation was dramatically reduced. Little further research in machine translation was conducted \n",
        "until the late 1980s when the first statistical machine translation systems were developed.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a0hd9QUAGzBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = article"
      ],
      "metadata": {
        "id": "E951qmJTCsYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "# @add_method(PacktDataAug)\n",
        "# def print_aug_ai_xlnet(self, df, col_dest=\"description\",\n",
        "#   from_model_name='facebook/wmt19-en-de', \n",
        "#   to_model_name='facebook/wmt19-de-en',\n",
        "#   bsize=3, aug_name='Augment'):\n",
        "#   aug_func = nlpaug.augmenter.word.BackTranslationAug(from_model_name=from_model_name,\n",
        "#     to_model_name=to_model_name)\n",
        "#   self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "#   return"
      ],
      "metadata": {
        "id": "KH_HXxY-BMpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path: xlnet-base-cased or gpt2\n",
        "text='It was a dark and stormy night'\n",
        "aug = nlpaug.augmenter.sentence.ContextualWordEmbsForSentenceAug(model_path='xlnet-base-cased')\n",
        "augmented_texts = aug.augment(text, n=3)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Texts:\")\n",
        "print(augmented_texts)"
      ],
      "metadata": {
        "id": "t8AJ-Es7FC9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-2"
      ],
      "metadata": {
        "id": "Mlhespw2s3af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlpaug.augmenter.sentence.ContextualWordEmbsForSentenceAug?"
      ],
      "metadata": {
        "id": "n_44ot3LNHh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTtBIFnuOvZm"
      },
      "outputs": [],
      "source": [
        "text = 'It was a dark and stormy night.'\n",
        "aug = nlpaug.augmenter.sentence.ContextualWordEmbsForSentenceAug(model_path='gpt2'\n",
        "  # , model_type='gpt2'\n",
        "  , force_reload = True,\n",
        "  min_length = 10,\n",
        "  max_length = 100,\n",
        "  # top_k = 2,\n",
        "  silence=True\n",
        "  )\n",
        "augmented_text = aug.augment(text)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"\\n***\\nAugmented Text:\")\n",
        "print(len(augmented_text))\n",
        "print(augmented_text[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = pluto.orig_text\n",
        "aug = nlpaug.augmenter.sentence.RandomSentAug()\n",
        "augmented_text = aug.augment(text)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"\\n***\\nAugmented Text:\")\n",
        "print(len(augmented_text))\n",
        "print(augmented_text[0])"
      ],
      "metadata": {
        "id": "xkNJ-xI9UBzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article = pluto.orig_text\n",
        "aug = nlpaug.augmenter.sentence.AbstSummAug(model_path='t5-base')\n",
        "augmented_text = aug.augment(article)\n",
        "print(\"Original:\")\n",
        "print(article)\n",
        "print(\"Augmented Text:\")\n",
        "print(augmented_text[0])"
      ],
      "metadata": {
        "id": "TsLLbsXzVRI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nlpaug.augmenter.sentence.LambadaAug?"
      ],
      "metadata": {
        "id": "QxeTqd6mKiPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# article = pluto.orig_text\n",
        "# aug = nlpaug.augmenter.sentence.LambadaAug(model_dir='t5-base')\n",
        "# augmented_text = aug.augment(article)\n",
        "# print(\"Original:\")\n",
        "# print(article)\n",
        "# print(\"Augmented Text:\")\n",
        "# print(augmented_text[0])"
      ],
      "metadata": {
        "id": "OLQaspkrV8B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# article = pluto.orig_text\n",
        "# aug = nlpaug.augmenter.sentence.AbstSummAug(model_path='bart-large-cnn')\n",
        "# augmented_text = aug.augment(article)\n",
        "# print(\"Original:\")\n",
        "# print(article)\n",
        "# print(\"Augmented Text:\")\n",
        "# print(augmented_text[0])"
      ],
      "metadata": {
        "id": "uFSNYLhfVRMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DKI7Q4dXVRPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dcer4IqvVRSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wr70zofkVRVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkT8iQwTVRYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bu4fS435UB7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(augmented_text)"
      ],
      "metadata": {
        "id": "ASFcXuVWHUi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "GJkzb4UWOvZm"
      },
      "outputs": [],
      "source": [
        "text2 = 'It was a dark and stormy night.'\n",
        "aug = nlpaug.augmenter.sentence.ContextualWordEmbsForSentenceAug(model_path='gpt2')\n",
        "augmented_text = aug.augment(text2,n=3)\n",
        "print(\"Original:\")\n",
        "print(text2)\n",
        "print(\"Augmented Text:\")\n",
        "print(augmented_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DistilGPT-2"
      ],
      "metadata": {
        "id": "9EgH6LNss7Hr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ik-sBUvOvZn"
      },
      "outputs": [],
      "source": [
        "aug = nlpaug.augmenter.sentence.ContextualWordEmbsForSentenceAug(model_path='distilgpt2')\n",
        "augmented_text = aug.augment(text)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Text:\")\n",
        "print(augmented_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DshLBm_UOvZn"
      },
      "source": [
        "# T5-Base"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@add_method(PacktDataAug)\n",
        "def _fetch_larger_font(self):\n",
        "  heading_properties = [('font-size', '20px')]\n",
        "  cell_properties = [('font-size', '18px'), ('text-align', 'left')]\n",
        "  dfstyle = [dict(selector=\"th\", props=heading_properties),\n",
        "    dict(selector=\"td\", props=cell_properties)]\n",
        "  return dfstyle"
      ],
      "metadata": {
        "id": "PWYurl0o-jAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%write\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _print_aug_ai(self, orig, aug_func, \n",
        "  bsize=2, aug_name='Augmented',is_larger_font=True):\n",
        "  aug = aug_func.augment(orig)\n",
        "  data = [[aug[0]]]\n",
        "  df_aug = pandas.DataFrame(data, columns=[aug_name])\n",
        "  #\n",
        "  if (bsize > 1):\n",
        "    for i in range(bsize-1):\n",
        "      aug = aug_func.augment(orig)\n",
        "      data = [[aug[0]]]\n",
        "      t = pandas.DataFrame(data, columns=[aug_name])\n",
        "      df_aug = df_aug.append(t, ignore_index=True)\n",
        "  #\n",
        "  with pandas.option_context(\"display.max_colwidth\", None):\n",
        "    if (is_larger_font):\n",
        "      # df_aug.style.set_properties(**{'text-align': 'left'})\n",
        "      # display(df_aug.style.set_properties(**{'text-align': 'left'}))\n",
        "      display(df_aug.style.set_table_styles(self._fetch_larger_font()))\n",
        "    else:\n",
        "      display(df_aug)\n",
        "  return df_aug\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ai_t5(self, orig, \n",
        "  bsize=2, \n",
        "  aug_name='T5_summary',\n",
        "  is_orig_control=True):\n",
        "  aug_func = nlpaug.augmenter.sentence.AbstSummAug(model_path='t5-base')\n",
        "  df = self._print_aug_ai(orig, aug_func,bsize=bsize, aug_name=aug_name)\n",
        "  return df"
      ],
      "metadata": {
        "id": "xT_x7vmz1Wfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_carroll = pluto.print_aug_ai_t5(pluto.orig_carroll_page, bsize=1)"
      ],
      "metadata": {
        "id": "JDwH5bq36Ln-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_carroll = pluto.print_aug_ai_t5(pluto.orig_carroll_page2, bsize=1)"
      ],
      "metadata": {
        "id": "LEhRXqR-X_fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_melville = pluto.print_aug_ai_t5(pluto.orig_melville_page, bsize=1)"
      ],
      "metadata": {
        "id": "r1oK3bhX_fyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_dickens = pluto.print_aug_ai_t5(pluto.orig_dickens_page, bsize=1)"
      ],
      "metadata": {
        "id": "mKxdKl75_f1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_self = pluto.print_aug_ai_t5(pluto.orig_self, bsize=1)"
      ],
      "metadata": {
        "id": "1K-FP4Vy_f4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scratch"
      ],
      "metadata": {
        "id": "EUgN2zp8_Yp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto._fetch_larger_font??"
      ],
      "metadata": {
        "id": "jY3gbT-36LrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tvgaz_5_6Lud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto._print_aug_batch??"
      ],
      "metadata": {
        "id": "WuQXCeNo1jV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4QDPvm6OvZn"
      },
      "outputs": [],
      "source": [
        "article = pluto.orig_melville_page\n",
        "\n",
        "aug = nlpaug.augmenter.sentence.AbstSummAug(model_path='t5-base')\n",
        "#augmented_text = aug.augment(article)\n",
        "augmented_text = aug.augment(article)\n",
        "print(\"Original:\")\n",
        "print(article)\n",
        "print(\"Augmented Text:\")\n",
        "augmented_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article = pluto.orig_carroll_page\n",
        "\n",
        "aug = nlpaug.augmenter.sentence.AbstSummAug(model_path='t5-base')\n",
        "#augmented_text = aug.augment(article)\n",
        "augmented_text = aug.augment(article)\n",
        "print(\"Original:\")\n",
        "print(article)\n",
        "print(\"Augmented Text:\")\n",
        "augmented_text"
      ],
      "metadata": {
        "id": "MzZOwboUsL8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article = pluto.orig_carroll_page\n",
        "\n",
        "aug = nlpaug.augmenter.sentence.AbstSummAug(model_path='t5-base')\n",
        "#augmented_text = aug.augment(article)\n",
        "augmented_text = aug.augment(article)\n",
        "print(\"Original:\")\n",
        "print(article)\n",
        "print(\"Augmented Text:\")\n",
        "augmented_text"
      ],
      "metadata": {
        "id": "lCptS6B3sMAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_text = aug.augment(pluto.orig_christie_page)\n",
        "print(\"Augmented Text:\")\n",
        "augmented_text"
      ],
      "metadata": {
        "id": "1tPJ8dokmf4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_text = aug.augment(pluto.orig_dickens_page)\n",
        "print(\"Augmented Text:\")\n",
        "augmented_text"
      ],
      "metadata": {
        "id": "qbddRiOrlS_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aliceâ€™s Adventures in Wonderland\n",
        "# by Lewis Carroll\n",
        "# THE MILLENNIUM FULCRUM EDITION 3.0"
      ],
      "metadata": {
        "id": "-5cikOnWnOCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_text = aug.augment(pluto.orig_self)\n",
        "print(\"Augmented Text:\")\n",
        "augmented_text"
      ],
      "metadata": {
        "id": "98XQrx4onOFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scratch aug the summary"
      ],
      "metadata": {
        "id": "BP92cAoZvkG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as naf\n",
        "from nlpaug.util import Action"
      ],
      "metadata": {
        "id": "bF1ng0PDQfmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pluto.t5_ai_summary_melville = 'Ishmael is a sailor who has a way of driving off the spleen and regulating the circulation. he says it is his substitute for pistol and ball to get to sea as soon as he can. almost all men in their degree, some time or other, cherish very nearly the same feelings.'\n",
        "# pluto.t5_ai_summary_carroll = 'a white rabbit with pink eyes ran close by. the rabbit took a watch out of its waistcoat-pocket, and then hurried on. she ran across the field after it, and was just in time to see it pop down a rabbit-hole.'\n",
        "# pluto.t5_ai_summary_christie = 'a group of depressed-looking females and three perspiring males tour Bulawayo. they all admired the tall lean figure and light-hearted manner with which he settled disputes. a peculiar-looking man is about the same height as Mr. Cade, but thickset and not nearly so good-looking.'\n",
        "# pluto.t5_ai_summary_dickeens = 'david rothkopf: spiritual revelations were conceded to England at favoured time. he says even the Cock-lane ghost had been laid only a round dozen of years. the spirits of this very year last past rapped out theirs, he writes.'\n",
        "# pluto.t5_ai_summary_self = 'text augmentation with machine learning (ML) is an advanced technique. we used a pre-trained ML model to create additional training NLP data.'\n"
      ],
      "metadata": {
        "id": "0Cw2GSTqnOIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'It was a dark and stormy night'\n",
        "aug_syn = naw.SynonymAug(aug_src='wordnet')\n",
        "# augmented_text = aug_syn.augment(text)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Synonym Text:\")\n",
        "for ii in range(5):\n",
        "    augmented_text = aug_syn.augment(text)\n",
        "    print(augmented_text)\n",
        "\n",
        "aug = naw.AntonymAug()\n",
        "# _text = 'Good boy is very good'\n",
        "_text = text\n",
        "\n",
        "print(\"Original:\")\n",
        "print(_text)\n",
        "print(\"Augmented Antonym Text:\")\n",
        "for ii in range(5):\n",
        "    augmented_text = aug.augment(_text)\n",
        "    print(augmented_text)"
      ],
      "metadata": {
        "id": "lS5LXIhsXVKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../input/nlpword2vecembeddingspretrained -l"
      ],
      "metadata": {
        "id": "WBtk6gigXVNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scratch aug the sum"
      ],
      "metadata": {
        "id": "EAjdXrSRxNri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'It was a dark and stormy night'\n",
        "# model_type: word2vec, glove or fasttext\n",
        "aug_w2v = naw.WordEmbsAug(\n",
        "#     model_type='word2vec', model_path='../input/nlpword2vecembeddingspretrained/GoogleNews-vectors-negative300.bin',\n",
        "    model_type='glove', model_path='glove.6B.300d.txt',\n",
        "    action=\"substitute\")\n",
        "# print(\"Original:\")\n",
        "# print(text)"
      ],
      "metadata": {
        "id": "fJsMgVGFXVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'It was a dark and stormy night.'\n",
        "#aug_w2v.aug_p=0.1\n",
        "aug_w2v.aug_p=0.5\n",
        "print(\"Augmented Text:\")\n",
        "for ii in range(5):\n",
        "    augmented_text = aug_w2v.augment(text)\n",
        "    print(augmented_text)"
      ],
      "metadata": {
        "id": "Z4D_sGrcXVWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Augmented Text:\")\n",
        "for ii in range(2):\n",
        "    augmented_text = aug_w2v.augment(pluto.t5_melville)\n",
        "    print(augmented_text)"
      ],
      "metadata": {
        "id": "f2C4Qyo3XVTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Augmented Text:\")\n",
        "for ii in range(2):\n",
        "    augmented_text = aug_w2v.augment(pluto.t5_summary_melville)\n",
        "    print(augmented_text)"
      ],
      "metadata": {
        "id": "Nakmpmzun0n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aug_w2v.aug_p=0.8\n",
        "# text = 'It was a dark and stormy night.'\n",
        "# print(\"Augmented Text:\")\n",
        "# for ii in range(5):\n",
        "#     augmented_text = aug_w2v.augment(text)\n",
        "#     print(augmented_text)"
      ],
      "metadata": {
        "id": "9KjIyE1Rn2HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT Augmentator\n",
        "text = 'It was a dark and stormy night.'\n",
        "TOPK=20 #default=100\n",
        "ACT = 'insert' #\"substitute\"\n",
        "\n",
        "aug_bert = naw.ContextualWordEmbsAug(\n",
        "    model_path='distilbert-base-uncased', \n",
        "    #device='cuda',\n",
        "    action=ACT, top_k=TOPK)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Text:\")\n",
        "for ii in range(5):\n",
        "    augmented_text = aug_bert.augment(text)\n",
        "    print(augmented_text)"
      ],
      "metadata": {
        "id": "zHbuFJUQY0U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'It was a dark and stormy night.'\n",
        "aug = naf.Sequential([\n",
        "    aug_bert,aug_w2v\n",
        "])\n",
        "\n",
        "aug.augment(text, n=10)"
      ],
      "metadata": {
        "id": "oe5bm6ITY0YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#flow"
      ],
      "metadata": {
        "id": "zC3Gsc8QyC55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #BERT Augmentator\n",
        "# text = 'It was a dark and stormy night.'\n",
        "# TOPK=20 #default=100\n",
        "# ACT = 'insert' #\"substitute\"\n",
        "import nlpaug.augmenter.word\n",
        "import nlpaug.augmenter.sentence\n",
        "import nlpaug.flow\n",
        "pluto.ai_aug_glove = nlpaug.augmenter.word.WordEmbsAug(\n",
        "#     model_type='word2vec', model_path='../input/nlpword2vecembeddingspretrained/GoogleNews-vectors-negative300.bin',\n",
        "    model_type='glove', model_path='glove.6B.300d.txt',\n",
        "    action=\"substitute\")\n",
        "#\n",
        "# text = 'It was a dark and stormy night.'\n",
        "#aug_w2v.aug_p=0.1\n",
        "pluto.ai_aug_glove.aug_p=0.5\n",
        "# print(\"Augmented Text:\")\n",
        "# for ii in range(5):\n",
        "#     augmented_text = pluto.ai_aug_glove.augment(text)\n",
        "#     print(augmented_text)\n",
        "#\n",
        "pluto.ai_aug_bert = nlpaug.augmenter.word.ContextualWordEmbsAug(\n",
        "    model_path='bert-base-uncased', \n",
        "    #device='cuda',\n",
        "    action='substitute', top_k=20)\n",
        "# print(\"Original:\")\n",
        "# print(text)\n",
        "# print(\"Augmented Text:\")\n",
        "# for ii in range(5):\n",
        "#     augmented_text = pluto.ai_aug_bert.augment(text)\n",
        "#     print(augmented_text)\n"
      ],
      "metadata": {
        "id": "96LvpOPdNeeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "import nlpaug\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ai_sequential(self, df, \n",
        "  aug_name=\"T5_summary\",\n",
        "  bsize=4):\n",
        "  aug_func = nlpaug.flow.Sequential([self.ai_aug_bert, self.ai_aug_glove])\n",
        "  orig = df[aug_name][0]\n",
        "  # print(orig)\n",
        "  self._print_aug_ai(orig, aug_func,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "aR5dVL-RNGpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_carroll.T5_summary[0]"
      ],
      "metadata": {
        "id": "Ux5lEe40U3Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_sequential(pluto.df_t5_carroll)"
      ],
      "metadata": {
        "id": "IvOfkZG_SpQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_sequential(pluto.df_t5_dickens)"
      ],
      "metadata": {
        "id": "JraL6RCQWtG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_sequential(pluto.df_t5_melville)"
      ],
      "metadata": {
        "id": "TdqKW0pzWtb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_sequential(pluto.df_t5_self)"
      ],
      "metadata": {
        "id": "kmz35pawWte_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scratch"
      ],
      "metadata": {
        "id": "dQzHcpVfXOft"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8wqdV6-VWth0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text3 = 'It was a dark and stormy night.'\n",
        "aug3 = naf.Sequential([\n",
        "    aug_bert,aug_w2v])\n",
        "\n",
        "aug3.augment(text2, n=10) "
      ],
      "metadata": {
        "id": "r8134rxBQ_F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = 'It was a dark and stormy night.'\n",
        "aug2 = naf.Sometimes([\n",
        "    aug_bert,aug_w2v\n",
        "],aug_p=0.5)\n",
        "\n",
        "aug2.augment(text2, n=10) # seems Sometimes has a bug, it still EveryTime, but results look better than sequential"
      ],
      "metadata": {
        "id": "Ij32AGwSY0bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_sometimes(pluto.df_t5_carroll,\n",
        "  col_dest='T5_summary',\n",
        "  action='insert',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "RAGd-0mKLi0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.t5_carroll"
      ],
      "metadata": {
        "id": "m26LWEEzLjHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = pluto.t5_summary_melville\n",
        "aug2 = naf.Sometimes([\n",
        "    aug_bert,aug_w2v\n",
        "],aug_p=0.5)\n",
        "\n",
        "aug2.augment(text2, n=4) # seems Sometimes has a bug, it still EveryTime, but results look better than sequential"
      ],
      "metadata": {
        "id": "bPk8uO-ZyFpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug2.augment(pluto.t5_ai_summary_carroll, n=4) "
      ],
      "metadata": {
        "id": "gIOaf1tDyFtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug2.augment(pluto.t5_ai_summary_christie, n=4) "
      ],
      "metadata": {
        "id": "ec3wrMl6yFwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug2.augment(pluto.t5_ai_summary_dickeens, n=4) "
      ],
      "metadata": {
        "id": "QKVs-mblyFzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug2.augment(pluto.t5_ai_summary_self, n=4) "
      ],
      "metadata": {
        "id": "LOeuFl-ryF5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MFqoDWLmyF8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scratch"
      ],
      "metadata": {
        "id": "W0TcPpR905Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'It was a dark and stormy night.'\n",
        "aug_w2v.aug_p=0.8\n",
        "aug = naf.Sequential([\n",
        "    aug_bert,aug_w2v\n",
        "])\n",
        "\n",
        "aug.augment(text, n=5)"
      ],
      "metadata": {
        "id": "yFtEug0YbSZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'It was a dark and stormy night.'\n",
        "aug_w2v.aug_p=1.8\n",
        "aug = naf.Sequential([\n",
        "    aug_bert,aug_w2v\n",
        "])\n",
        "\n",
        "aug.augment(text, n=5)"
      ],
      "metadata": {
        "id": "do3KX21obSch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''It was a dark and stormy night.\n",
        "I was lost and now I am found.'''\n",
        "aug_w2v.aug_p=0.2\n",
        "aug = naf.Sequential([\n",
        "    aug_bert,aug_w2v\n",
        "])\n",
        "\n",
        "aug.augment(text, n=5)"
      ],
      "metadata": {
        "id": "2mJtoujmbSfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = pluto.orig_carroll_page\n",
        "aug_w2v.aug_p=0.2\n",
        "aug = naf.Sequential([\n",
        "    aug_bert,aug_w2v\n",
        "])\n",
        "\n",
        "aug.augment(text, n=5)"
      ],
      "metadata": {
        "id": "okA7Se4obSie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFtAt0fPp9qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ow0iDtqup9t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A80-5mg6p9xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sYzKkalOp9z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E3uT_o8SbSlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentencepiece.__version__)"
      ],
      "metadata": {
        "id": "0wnoOdI6Y0ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece==0.1.96\n",
        "import sentencepiece"
      ],
      "metadata": {
        "id": "SCD3WkYpbC2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'It was a dark and stormy night.'\n",
        "aug = nas.ContextualWordEmbsForSentenceAug(\n",
        "    # model_path='gpt2'\n",
        "        model_path='distilgpt2', \n",
        "    # model_path='xlnet-base-cased',\n",
        "\n",
        "    # top_k=TOPK\n",
        ")\n",
        "\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Text:\")\n",
        "for ii in range(5):\n",
        "    augmented_text = aug.augment(text)\n",
        "    print(augmented_text)"
      ],
      "metadata": {
        "id": "3Ueyn3GgbC6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I4JNNGMRbC9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yHRFsPkSbKE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetTokenizer, XLNetModel\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "model = XLNetModel.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state"
      ],
      "metadata": {
        "id": "jq4vi8u-bKIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "id": "2Fi4GpHHbKLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G-0yb91AbKN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {
        "id": "-8QoaB1uZj5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# f = 'Data-Augmentation-with-Python'\n",
        "# os.chdir(f)\n",
        "# !git add -A\n",
        "# !git config --global user.email \"duc.haba@gmail.com\"\n",
        "# !git config --global user.name \"duchaba\"\n",
        "# !git commit -m \"end of session\"\n",
        "# # do the git push in the xterm console\n",
        "# #!git push"
      ],
      "metadata": {
        "id": "-uqlOsMlZm5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install colab-xterm\n",
        "# %load_ext colabxterm\n",
        "# %xterm"
      ],
      "metadata": {
        "id": "3n1wuFxaZm9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0Rcgm5hZnAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0B8INRAZnDW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "EUgN2zp8_Yp0",
        "dQzHcpVfXOft",
        "W0TcPpR905Wo"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}