{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duchaba/Data-Augmentation-with-Python/blob/main/data_augmentation_with_python_chapter_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation with Python, Chapter 5"
      ],
      "metadata": {
        "id": "rad13-eq4fAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ» Welcome to Chapter 4, \"Image Augmentation for Segmentation\"\n",
        "\n",
        "In this chapter, you will learn about Text augmentation and how to code the methods in Python. In particular, the topics are as follows: \n",
        "\n",
        "- Character augmenting \n",
        "\n",
        "- Word augmenting \n",
        "\n",
        "- Sentence and flow augmenting \n",
        "\n",
        "- Text augmentation libraries \n",
        "\n",
        "- Reinforce learning through Python code "
      ],
      "metadata": {
        "id": "1DlWAB8G4ijz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up: Bring back Pluto\n"
      ],
      "metadata": {
        "id": "ZZ8-JIXv6jmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœ‹ STOP: Pull Method\n",
        "\n",
        "- There are two methods to bring back Pluto.\n",
        "\n",
        "1. Clone from GitHut (or update by doing \"git pull if you have clone it before)\n",
        "\n",
        "2. Or retrieve from an URL. The URL can be the GitHub URL or an URL the you store your Pluto python file from the first lesson.\n",
        "\n",
        "- Do one, but not both."
      ],
      "metadata": {
        "id": "dOpu3yYb6rK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GitHub Clone"
      ],
      "metadata": {
        "id": "4b52gSlp60SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# git version should be 2.17.1 or higher\n",
        "!git --version"
      ],
      "metadata": {
        "id": "6oeDAu1u6zWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://github.com/PacktPublishing/Data-Augmentation-with-Python'\n",
        "url = 'https://github.com/duchaba/Data-Augmentation-with-Python'\n",
        "!git clone {url}"
      ],
      "metadata": {
        "id": "J9buwUR767Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch file from URL (Optional)\n",
        "\n",
        "- Uncommend the below 2 code cells if you want to use URL and not Git Clone"
      ],
      "metadata": {
        "id": "lOawA01L7Ok0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# #\n",
        "# def fetch_file(url, dst):\n",
        "#   downloaded_obj = requests.get(url)\n",
        "#   with open(dst, \"wb\") as file:\n",
        "#     file.write(downloaded_obj.content)\n",
        "#   return"
      ],
      "metadata": {
        "id": "HsmQ7rgj67Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# url = ''\n",
        "# dst = 'pluto_chapter_1.py'\n",
        "# fetch_file(url,dst)"
      ],
      "metadata": {
        "id": "_nKp0nxT67aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pluto\n",
        "\n",
        "- Instantiate up Pluto, aka. \"Pluto, wake up!\""
      ],
      "metadata": {
        "id": "6462KTtr7cFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load and run the pluto chapter 1 Python code.\n",
        "pluto_file = 'Data-Augmentation-with-Python/pluto/pluto_chapter_2.py'\n",
        "%run {pluto_file}"
      ],
      "metadata": {
        "id": "u3zbkOO86_WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Double check on the server environments"
      ],
      "metadata": {
        "id": "yhRR0JSf746h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.say_sys_info()"
      ],
      "metadata": {
        "id": "nBIw7fiI6_Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto_chapter_5 = 'Data-Augmentation-with-Python/pluto/pluto_chapter_5.py'\n",
        "!cp {pluto_file} {pluto_chapter_5}"
      ],
      "metadata": {
        "id": "Gfx9Ai5Opyqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœ‹ STOP: Reinitalize Kaggle\n",
        "\n",
        "- Install the following libraries, and import it on the Notebook.\n",
        "- Follow by initialize Kaggle username, key and fetch methods.\n",
        "- STOP: Update your Kaggle access username or key first."
      ],
      "metadata": {
        "id": "kQ6ap39x8HyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- : --------------------\n",
        "# READ ME\n",
        "# Chapter 2 begin:\n",
        "# Install the following libraries, and import it on the Notebook.\n",
        "# Follow by initialize Kaggle username, key and fetch methods.\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "# -------------------- : --------------------\n",
        "\n",
        "!pip install opendatasets --upgrade\n",
        "import opendatasets\n",
        "print(\"\\nrequired version 0.1.22 or higher: \", opendatasets.__version__)\n",
        "\n",
        "!pip install pyspellchecker \n",
        "import spellchecker\n",
        "print(\"\\nRequired version 0.7+\", spellchecker.__version__)\n",
        "\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "pluto.remember_kaggle_access_keys(\"duchaba\", \"0c737c90feacb5c56232b0d7c24e8664\")\n",
        "pluto._write_kaggle_credit()\n",
        "import kaggle\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_comp_data(self,cname):\n",
        "  #self._write_kaggle_credit()  # need to run only once.\n",
        "  path = pathlib.Path(cname)\n",
        "  kaggle.api.competition_download_cli(str(path))\n",
        "  zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
        "  return\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_dataset(self,url,dest=\"kaggle\"):\n",
        "  #self._write_kaggle_credit()    # need to run only once.\n",
        "  opendatasets.download(url,data_dir=dest)\n",
        "  return\n",
        "# -------------------- : --------------------\n"
      ],
      "metadata": {
        "id": "sf4Obdp-77CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Kaggle Data"
      ],
      "metadata": {
        "id": "5BfHiMQE8XWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NetFlix"
      ],
      "metadata": {
        "id": "WSWTfhPU9YjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "url = 'https://www.kaggle.com/datasets/infamouscoder/dataset-netflix-shows'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ],
      "metadata": {
        "id": "_TEFhsYs77Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'kaggle/dataset-netflix-shows/netflix_titles.csv'\n",
        "pluto.df_netflix_data = pluto.fetch_df(f)\n",
        "pluto.df_netflix_data.head(3)"
      ],
      "metadata": {
        "id": "_GHi9DnM77Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_batch_text(pluto.df_netflix_data)"
      ],
      "metadata": {
        "id": "FJP18_-M77Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.count_word(pluto.df_netflix_data)\n",
        "pluto.df_netflix_data.head()"
      ],
      "metadata": {
        "id": "EC_P1qsP77RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_word_count(pluto.df_netflix_data)"
      ],
      "metadata": {
        "id": "HTXz32vF6_cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install missingno"
      ],
      "metadata": {
        "id": "QAxo1zXThdkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "pluto.version = 5.0\n",
        "import missingno\n",
        "@add_method(PacktDataAug)\n",
        "def draw_text_null_data(self, df, color=(0.3,0.36,0.44)):\n",
        "  canvas, pic = matplotlib.pyplot.subplots(1, 1, figsize=(16, 6))\n",
        "  missingno.matrix(df,color=color,ax=pic)\n",
        "  pic.set_title('Missing Data (Null Value)')\n",
        "  pic.set_xlabel('Solid is has data. White line is missing/null data.')\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return"
      ],
      "metadata": {
        "id": "uN3KPZBbhadh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_text_null_data(pluto.df_netflix_data)"
      ],
      "metadata": {
        "id": "-MaTeOMghuR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install wordcloud"
      ],
      "metadata": {
        "id": "oBGVKXYGh_z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "import nltk\n",
        "import wordcloud"
      ],
      "metadata": {
        "id": "uwenoLbCh_48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Nltk version 3.7: actual: ', nltk.__version__)\n",
        "print('WordCloud version 1.8.2.2: actual: ', wordcloud.__version__)"
      ],
      "metadata": {
        "id": "bSauNuC1wGzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "import re\n",
        "@add_method(PacktDataAug)\n",
        "def _draw_image_wordcloud(self, words_str, xignore_words='cat', title='Word Cloud:'):\n",
        "  canvas, pic = matplotlib.pyplot.subplots(1, 1, figsize=(16, 8))\n",
        "  img = wordcloud.WordCloud(width = 1600, \n",
        "    height = 800, \n",
        "    background_color ='white',\n",
        "    stopwords = xignore_words, \n",
        "    min_font_size = 10).generate(words_str) \n",
        "  pic.imshow(img)\n",
        "  pic.set_title(title)\n",
        "  pic.set_xlabel(f'Approximate Words: {int(len(words_str) / 5)}')\n",
        "  pic.tick_params(left = False, right = False, labelleft = False,\n",
        "    labelbottom = False, bottom = False)\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return\n",
        "  #\n",
        "@add_method(PacktDataAug)\n",
        "def draw_text_wordcloud(self, df_1column, xignore_words='cat', title='Word Cloud:'):\n",
        "  orig = df_1column.str.cat()\n",
        "  clean = re.sub('[^A-Za-z0-9 ]+', '', orig)\n",
        "  self._draw_image_wordcloud(clean, xignore_words=xignore_words,title=title)\n",
        "  return"
      ],
      "metadata": {
        "id": "f2Y799hsv7Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_text_wordcloud(pluto.df_netflix_data.description, \n",
        "  xignore_words=wordcloud.STOPWORDS, \n",
        "  title='Word Cloud: Netflix Movie Review')"
      ],
      "metadata": {
        "id": "OaGD2wtPANLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x = ' '.join(wordcloud.STOPWORDS)\n",
        "# pluto._draw_image_wordcloud(x,title='Word Cloud: StopWords')"
      ],
      "metadata": {
        "id": "pxAaf8up1DhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Twitter"
      ],
      "metadata": {
        "id": "ZurnPA1u-T8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @add_method(PacktDataAug)\n",
        "# def fetch_df(self, csv):\n",
        "#   df = pandas.read_csv(csv, encoding='latin-1')\n",
        "#   return df"
      ],
      "metadata": {
        "id": "FRjmqGVn-msp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "%%time\n",
        "#url = 'https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification'\n",
        "url = 'https://www.kaggle.com/datasets/mayurdalvi/twitter-sentiments-analysis-nlp'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ],
      "metadata": {
        "id": "WePFW0tu6_fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove white space in directory and filename\n",
        "# run this until no error/output\n",
        "f = 'kaggle/twitter-sentiments-analysis-nlp'\n",
        "#!find {f} -name \"* *\" -type d | rename 's/ /_/g'\n",
        "!find {f} -name \"* *\" -type f | rename 's/ /_/g'"
      ],
      "metadata": {
        "id": "ms7jgEcrKpIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'kaggle/twitter-sentiments-analysis-nlp/Twitter_Sentiments.csv'\n",
        "pluto.df_twitter_data = pluto.fetch_df(f)\n",
        "pluto.df_twitter_data.head(3)"
      ],
      "metadata": {
        "id": "HhaenARf-mmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_batch_text(pluto.df_twitter_data,cols=['label', 'tweet'])"
      ],
      "metadata": {
        "id": "onbBfDI--mvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install filter-profanity\n",
        "import profanity"
      ],
      "metadata": {
        "id": "E7s_6RTlBXJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean up\n",
        "import re\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def _clean_text(self,x):\n",
        "  return (re.sub('[^A-Za-z0-9 .,!?#@]+', '', str(x)))\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def _clean_bad_word(self,x):\n",
        "  return (profanity.censor_profanity(x, ''))\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def clean_text(self, df):\n",
        "  df['clean_tweet'] = df.tweet.apply(self._clean_text)\n",
        "  df['clean_tweet'] = df['clean_tweet'].apply(self._clean_bad_word)\n",
        "  return df"
      ],
      "metadata": {
        "id": "R7NuXRci5wC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pluto.clean_text(pluto.df_twitter_data)\n",
        "pluto.df_twitter_data.head()"
      ],
      "metadata": {
        "id": "RDqqtRY883yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_batch_text(pluto.df_twitter_data, cols=['label', 'clean_tweet'])"
      ],
      "metadata": {
        "id": "ViaQTmnBc-0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# double check on clean tweets\n",
        "print('clean: ', pluto.df_twitter_data.clean_tweet[13538], ' : original: ', \n",
        "  pluto.df_twitter_data.tweet[13538], ': label: ', pluto.df_twitter_data.label[13538])"
      ],
      "metadata": {
        "id": "3cVkaqIveWwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# double check on clean tweets\n",
        "with pandas.option_context(\"display.max_colwidth\", None):\n",
        "  display(pluto.df_twitter_data[pluto.df_twitter_data.label == 1].sample(10))"
      ],
      "metadata": {
        "id": "8uKcbMAefmfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.count_word(pluto.df_twitter_data,col_dest='clean_tweet')\n",
        "pluto.draw_word_count(pluto.df_twitter_data)"
      ],
      "metadata": {
        "id": "wsyzuXJ_-my0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_text_null_data(pluto.df_twitter_data)"
      ],
      "metadata": {
        "id": "pzqZtxaIh2lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_text_wordcloud(pluto.df_twitter_data.clean_tweet,\n",
        "  xignore_words=wordcloud.STOPWORDS,\n",
        "  title='Clean Tweets Word Cloud')"
      ],
      "metadata": {
        "id": "QBGppWuskKZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### export (aka drop or save) data file"
      ],
      "metadata": {
        "id": "iubboKaOM5-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _drop_df_file(self, df,fname,type='csv',sep='~'):\n",
        "  df.to_csv(fname,sep=sep)\n",
        "  return "
      ],
      "metadata": {
        "id": "oVO43N-Dh2pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'Data-Augmentation-with-Python/pluto_data/netflix_data.csv'\n",
        "pluto._drop_df_file(pluto.df_netflix_data, f)"
      ],
      "metadata": {
        "id": "FDswusz3LTfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !head '/content/Data-Augmentation-with-Python/pluto_data/twitter_data.csv'"
      ],
      "metadata": {
        "id": "sQIRUAwiKSGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'Data-Augmentation-with-Python/pluto_data/twitter_data.csv'\n",
        "pluto._drop_df_file(pluto.df_twitter_data, f)"
      ],
      "metadata": {
        "id": "EmYEusRiMkSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZqCjjxuOvZN"
      },
      "source": [
        "# Character Augmenter<a class=\"anchor\" id=\"chara_aug\">\n",
        "\n",
        "Augmenting data in character level. Possible scenarios include image to text and chatbot. During recognizing text from image, we need to optical character recognition (OCR) model to achieve it but OCR introduces some errors such as recognizing \"o\" and \"0\". `OCRAug` simulate these errors to perform the data augmentation. For chatbot, we still have typo even though most of application comes with word correction. Therefore, `KeyboardAug` is introduced to simulate this kind of errors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug"
      ],
      "metadata": {
        "id": "rtHdmFVaPBtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug\n",
        "import nlpaug.augmenter\n",
        "import nlpaug.augmenter.char\n",
        "import nlpaug.augmenter.word\n",
        "print('version 1.1.11, actual: ',nlpaug.__version__)"
      ],
      "metadata": {
        "id": "4gs85bUcGTXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.orig_text = 'It was the best of times. It was the worst of times. It was the age of wisdom. It was the age of foolishness. It was the epoch of belief. It was the epoch of incredulity.'"
      ],
      "metadata": {
        "id": "6nl9A5n1G_WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _print_aug_batch(self, df, aug_func, col_dest=\"description\",bsize=3, aug_name='Augmented'):\n",
        "  col_name = [aug_name, 'Original']\n",
        "  aug = aug_func.augment(self.orig_text, n=1)\n",
        "  data = [[aug[0], self.orig_text]]\n",
        "  df_aug = pandas.DataFrame(data, columns=col_name)\n",
        "  orig = df[col_dest].sample(bsize)\n",
        "  for tx in orig:\n",
        "    aug = aug_func.augment(tx, n=1)\n",
        "    data = [[aug[0], tx]]\n",
        "    t = pandas.DataFrame(data, columns=col_name)\n",
        "    df_aug = df_aug.append(t, ignore_index=True)\n",
        "  #\n",
        "  with pandas.option_context(\"display.max_colwidth\", None):\n",
        "    display(df_aug.head(bsize+1))\n",
        "  return"
      ],
      "metadata": {
        "id": "_OhmyNQRHIfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OCR augmenting"
      ],
      "metadata": {
        "id": "sAX4XyY6bpW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ocr(self, df, col_dest=\"description\",bsize=3, aug_name='Augmented'):\n",
        "  aug_func = nlpaug.augmenter.char.OcrAug()\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "RUz21pdqYv3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ocr(pluto.df_netflix_data, col_dest='description',aug_name='OCR Augment')"
      ],
      "metadata": {
        "id": "sb_tMYrxY9nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ocr(pluto.df_twitter_data, col_dest='clean_tweet',aug_name='OCR Augment')"
      ],
      "metadata": {
        "id": "NtOYQz1FY9qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### scratch"
      ],
      "metadata": {
        "id": "AROAe3dxTCId"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egKaauRNOvZM"
      },
      "outputs": [],
      "source": [
        "# import nlpaug.augmenter.char as nac\n",
        "# import nlpaug.augmenter.word as naw\n",
        "# import nlpaug.augmenter.sentence as nas\n",
        "# import nlpaug.flow as nafc\n",
        "\n",
        "# from nlpaug.util import Action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOW3zbk8OvZM"
      },
      "outputs": [],
      "source": [
        "# #text = 'The quick brown fox jumps over the lazy dog .'\n",
        "# text = 'It was the best of times. It was the worst of times. It was the age of wisdom. It was the age of foolishness. It was the epoch of belief. It was the epoch of incredulity.'\n",
        "# print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHDd-yZcOvZQ"
      },
      "source": [
        "## Keyboard Augmenter<a class=\"anchor\" id=\"keyboard_aug\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOg0vDdbOvZQ"
      },
      "source": [
        "##### Substitute character by keyboard distance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_keyboard(self, df, col_dest=\"description\",bsize=3, aug_name='Keyboard Augment'):\n",
        "  aug_func = nlpaug.augmenter.char.KeyboardAug()\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "YlB5M1oPeDpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_keyboard(pluto.df_netflix_data, col_dest='description',aug_name='Keyboard Augment')"
      ],
      "metadata": {
        "id": "hWOa5vpweVKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_keyboard(pluto.df_twitter_data, col_dest='clean_tweet',aug_name='Keyboard Augment')"
      ],
      "metadata": {
        "id": "0_nCXoCAeVN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07pLIh0ZOvZR"
      },
      "source": [
        "## Random Augmenter<a class=\"anchor\" id=\"random_aug\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NksgmkHJOvZR"
      },
      "source": [
        "##### Insert character randomly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_char_random(self, df, action='insert', col_dest=\"description\",bsize=3, aug_name='Augment'):\n",
        "  aug_func = nlpaug.augmenter.char.RandomCharAug(action=action)\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "3yEFMY17guY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_char_random(pluto.df_netflix_data, action='insert', col_dest='description', aug_name='Random Insert Augment')"
      ],
      "metadata": {
        "id": "yeGr1b7qTaoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_char_random(pluto.df_netflix_data, action='delete', col_dest='description', aug_name='Random Delete Augment')"
      ],
      "metadata": {
        "id": "IiXwaqp2Ta0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_char_random(pluto.df_netflix_data, action='substitute', col_dest='description', aug_name='Random Substitute Augment')"
      ],
      "metadata": {
        "id": "J9oLzmMqUDTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_char_random(pluto.df_netflix_data, action='swap', col_dest='description', aug_name='Random Swap Augment')"
      ],
      "metadata": {
        "id": "wMnc0_4tUDXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_char_random(pluto.df_twitter_data, action='insert', col_dest='clean_tweet', aug_name='Random Insert Augment')"
      ],
      "metadata": {
        "id": "vmemvezFUDaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_char_random(pluto.df_twitter_data, action='delete', col_dest='clean_tweet', aug_name='Random Delete Augment')"
      ],
      "metadata": {
        "id": "AtuG0YkdUDdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_char_random(pluto.df_twitter_data, action='substitute', col_dest='clean_tweet', aug_name='Random Substitute Augment')"
      ],
      "metadata": {
        "id": "nLM2luSNUDgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_char_random(pluto.df_twitter_data, action='swap', col_dest='clean_tweet', aug_name='Random Swap Augment')"
      ],
      "metadata": {
        "id": "dXQmgum3UDjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2jTTIBjOvZV"
      },
      "source": [
        "# Word Augmenter<a class=\"anchor\" id=\"word_aug\"></a>\n",
        "\n",
        "Besides character augmentation, word level is important as well. We make use of word2vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014), fasttext (Joulin et al., 2016), BERT(Devlin et al., 2018) and wordnet to insert and substitute similar word. `Word2vecAug`,  `GloVeAug` and `FasttextAug` use word embeddings to find most similar group of words to replace original word. On the other hand, `BertAug` use language models to predict possible target word. `WordNetAug` use statistics way to find the similar group of words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfCX_OBFOvZV"
      },
      "source": [
        "### Misspell Augmenter<a class=\"anchor\" id=\"spelling_aug\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98-Qs4wUOvZV"
      },
      "source": [
        "##### Substitute word by spelling mistake words dictionary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_word_misspell(self, df, col_dest=\"description\",bsize=3, aug_name='Augment'):\n",
        "  aug_func = nlpaug.augmenter.word.SpellingAug()\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "cKXwiAXgWO8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_misspell(pluto.df_netflix_data, col_dest='description', aug_name='Word Spelling Augment')"
      ],
      "metadata": {
        "id": "ha0e6lcdXVPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_misspell(pluto.df_twitter_data, col_dest='clean_tweet', aug_name='Word Spelling Augment')"
      ],
      "metadata": {
        "id": "ohHaLHRHXvtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcPTut6FOvZi"
      },
      "source": [
        "### Split Augmenter<a class=\"anchor\" id=\"split_aug\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZJhHv9HOvZi"
      },
      "source": [
        "##### Split word to two tokens randomly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_word_split(self, df, col_dest=\"description\",bsize=3, aug_name='Augment'):\n",
        "  aug_func = nlpaug.augmenter.word.SplitAug()\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "2D0ybu_1YDog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_split(pluto.df_netflix_data, col_dest='description', aug_name='Word Split Augment')"
      ],
      "metadata": {
        "id": "IML8dabSYRc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_split(pluto.df_twitter_data, col_dest='clean_tweet', aug_name='Word Split Augment')"
      ],
      "metadata": {
        "id": "lTfSH_rPYRgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOjTDye8OvZf"
      },
      "source": [
        "### Random Word Augmenter<a class=\"anchor\" id=\"random_word_aug\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_word_random(self, df, action='swap', col_dest=\"description\",bsize=3, aug_name='Augment'):\n",
        "  aug_func = nlpaug.augmenter.word.RandomWordAug(action=action)\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "OP0EgFV1ZS4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_random(pluto.df_netflix_data, action='swap', col_dest='description', aug_name='Word Random Swap Augment')"
      ],
      "metadata": {
        "id": "t0_1pjpuaX9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_random(pluto.df_netflix_data, action='substitute', col_dest='description', aug_name='Word Random Substitude Augment')"
      ],
      "metadata": {
        "id": "ux703ByVaYA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_random(pluto.df_netflix_data, action='crop', col_dest='description', aug_name='Word Random Crop Augment')"
      ],
      "metadata": {
        "id": "Fz7grRQYaYFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_random(pluto.df_netflix_data, action='delete', col_dest='description', aug_name='Word Random Delete Augment')"
      ],
      "metadata": {
        "id": "jLfWfnT5aYH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_random(pluto.df_twitter_data, action='swap', col_dest='clean_tweet', aug_name='Word Random Swap Augment')"
      ],
      "metadata": {
        "id": "6kFTA5XkaYK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_random(pluto.df_twitter_data, action='substitute', col_dest='clean_tweet', aug_name='Word Random Substitute Augment')"
      ],
      "metadata": {
        "id": "MLWj8WKzaYOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_random(pluto.df_twitter_data, action='crop', col_dest='clean_tweet', aug_name='Word Random Crop Augment')"
      ],
      "metadata": {
        "id": "g493xRrDaYSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_random(pluto.df_twitter_data, action='delete', col_dest='clean_tweet', aug_name='Word Random Delete Augment')"
      ],
      "metadata": {
        "id": "nETKRYFTaYVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjmXSJndOvZd"
      },
      "source": [
        "### Synonym Augmenter<a class=\"anchor\" id=\"synonym_aug\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "9RxXSmnydJLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "83ODKdEYPowa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOImDH4QOvZd"
      },
      "source": [
        "##### Substitute word by WordNet's synonym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_word_synonym(self, df, col_dest=\"description\",bsize=3, aug_name='Augment'):\n",
        "  aug_func = nlpaug.augmenter.word.SynonymAug(aug_src='wordnet')\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "QrJnm8k1dXAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_synonym(pluto.df_netflix_data, col_dest='description', aug_name='Synonym WordNet Augment')"
      ],
      "metadata": {
        "id": "y075AG5jdand"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_synonym(pluto.df_twitter_data, col_dest='clean_tweet', aug_name='Synonym WordNet Augment')"
      ],
      "metadata": {
        "id": "zOcCjlNkdaq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ0_QmVUOvZe"
      },
      "source": [
        "##### Substitute word by PPDB's synonym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk.download('ppdb-2.0-s-all')"
      ],
      "metadata": {
        "id": "LZC1ybaFRrSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neEraHk_OvZe"
      },
      "outputs": [],
      "source": [
        "# aug = naw.SynonymAug(aug_src='ppdb', model_path='ppdb-2.0-s-all')\n",
        "# augmented_text = aug.augment(text)\n",
        "# print(\"Original:\")\n",
        "# print(text)\n",
        "# print(\"Augmented Text:\")\n",
        "# print(augmented_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY7cu6wUOvZe"
      },
      "source": [
        "### Antonym Augmenter<a class=\"anchor\" id=\"antonym_aug\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_word_antonym(self, df, col_dest=\"description\",bsize=3, aug_name='Augment'):\n",
        "  aug_func = nlpaug.augmenter.word.AntonymAug()\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "PvF8q32eeysk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_antonym(pluto.df_netflix_data, col_dest='description',aug_name='Antonym Augment')"
      ],
      "metadata": {
        "id": "7tqxTK-1eyvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_antonym(pluto.df_twitter_data, col_dest='clean_tweet',aug_name='Antonym Augment')"
      ],
      "metadata": {
        "id": "FGJEo3vHeyzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC0Vb6x9OvZk"
      },
      "source": [
        "### Reserved Word Augmenter<a class=\"anchor\" id=\"reserved_aug\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_word_reserved(self, df, col_dest=\"description\",reserved_tokens=None,bsize=3, aug_name='Augment'):\n",
        "  aug_func = nlpaug.augmenter.word.ReservedAug(reserved_tokens=reserved_tokens)\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "Vl927YB886BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "pluto.reserved_control = [['wisdom', 'sagacity', 'intelligence', 'prudence'],\n",
        "  ['foolishness', 'folly', 'idiocy', 'stupidity']]"
      ],
      "metadata": {
        "id": "LasXSvw186OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "pluto.reserved_netflix = [['family','household', 'brood', 'unit', 'families'],\n",
        "  ['life','existance', 'entity', 'creation'],\n",
        "  ['love', 'warmth', 'endearment','tenderness']]\n",
        "pluto.reserved_netflix = pluto.reserved_control + pluto.reserved_netflix"
      ],
      "metadata": {
        "id": "Ilef_J_987PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pluto.reserved_netflix"
      ],
      "metadata": {
        "id": "GgVoW26Z_aax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_reserved(pluto.df_netflix_data, col_dest='description', reserved_tokens=pluto.reserved_netflix, aug_name='Netflix Reserved word augment')"
      ],
      "metadata": {
        "id": "bY2PVusC_ad7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_5}\n",
        "\n",
        "pluto.reserved_twitter = [['user', 'users', 'customer', 'client','people','member','shopper'],\n",
        "  ['happy', 'cheerful', 'joyful', 'carefree'],\n",
        "  ['time','clock','hour']]\n",
        "pluto.reserved_twitter = pluto.reserved_control + pluto.reserved_twitter"
      ],
      "metadata": {
        "id": "y6ugzuz2_ahT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pluto.reserved_twitter"
      ],
      "metadata": {
        "id": "9n-tJ8qqD1rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_word_reserved(pluto.df_twitter_data, col_dest='clean_tweet', reserved_tokens=pluto.reserved_twitter,aug_name='Twitter Reserved word augment')"
      ],
      "metadata": {
        "id": "oJz48SZ9D1vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# end of chapter 5"
      ],
      "metadata": {
        "id": "ByK2v2hxOPLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push up all changes (Optional)"
      ],
      "metadata": {
        "id": "LEj7fgaIN9_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- username: duchaba\n",
        "\n",
        "- password: [use the token]"
      ],
      "metadata": {
        "id": "lHXRf21BT9N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# f = 'Data-Augmentation-with-Python'\n",
        "# os.chdir(f)\n",
        "# !git add -A\n",
        "# !git config --global user.email \"duc.haba@gmail.com\"\n",
        "# !git config --global user.name \"duchaba\"\n",
        "# !git commit -m \"end of session\"\n",
        "# # do the git push in the xterm console\n",
        "# #!git push"
      ],
      "metadata": {
        "id": "eSXJKJFlOEeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%script false --no-raise-error  #temporary stop execute for export file"
      ],
      "metadata": {
        "id": "JMJgBjC1Px5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzO7lDYDWeLz"
      },
      "source": [
        "# Summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2iUPf3EWePd"
      },
      "source": [
        "Every chaper will begin with same base class \"PacktDataAug\".\n",
        "\n",
        "âœ‹ FAIR WARNING:\n",
        "\n",
        "- The coding uses long and complete function path name.\n",
        "\n",
        "- Pluto wrote the code for easy to understand and not for compactness, fast execution, nor cleaverness.\n",
        "\n",
        "- Use Xterm to debug cloud server\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install colab-xterm\n",
        "# %load_ext colabxterm\n",
        "# %xterm"
      ],
      "metadata": {
        "id": "vXRG3KaeWbGx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlpaug_dev",
      "language": "python",
      "name": "nlpaug_dev"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}