{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duchaba/Data-Augmentation-with-Python/blob/main/data_augmentation_with_python_chapter_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5EqgaYW08Cm"
      },
      "source": [
        "# ðŸŒ» Welcome to Chapter 2, Biases In Data Augmentation\n",
        "\n",
        "---\n",
        "\n",
        "I am glad to see you using this Python Notebook. ðŸ•\n",
        "\n",
        "The Python Notebook is an integral part of the book. You can add new â€œcode cellsâ€ to extend the functions, add your data, and explore new possibilities, such as downloading additional real-world datasets from the Kaggle website and coding the **Fun challenges**. Furthermore, the book has **Fun facts**, in-depth discussion about augmentation techniques, and Pluto, an imaginary Siberian Huskey coding companion. Together they will guide you every steps of the way. \n",
        "\n",
        "Pluto encourages you to copy or save a copy of this Python Notebook to your local space and add the â€œtext cellsâ€ to keep your notes. In other words, read the book and copy the relevant concept to this Python Notebookâ€™s text-cells. Thus, you can have the explanation, note, original code, your code, and any crazy future ideas in one place.  \n",
        "\n",
        "\n",
        "ðŸ’— I hope you enjoy reading the book and hacking code as much as I enjoy writing it. \n",
        "\n",
        "\n",
        "## ðŸŒŸ Amazon Book\n",
        "\n",
        "---\n",
        "\n",
        "- The book is available on the Amazon Book website: \n",
        "  - https://www.amazon.com/dp/1803246456\n",
        "\n",
        "  - Author: Duc Haba\n",
        "  - Published: 2023\n",
        "  - Page count: 390+\n",
        "\n",
        "\n",
        "- The original Python Notebook is on: \n",
        "\n",
        "  - https://github.com/PacktPublishing/Data-Augmentation-with-Python/blob/main/Chapter_2/data_augmentation_with_python_chapter_2.ipynb \n",
        "\n",
        "- ðŸš€ Click on the blue \"Open in Colab\" button at the top of this page to begin hacking.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr2G6GSmF_za"
      },
      "source": [
        "# ðŸ˜€ Excerpt from Chapter 2, Biases In Data Augmentation\n",
        "\n",
        "---\n",
        "\n",
        "> In case you havenâ€™t bought the book. Here is an excerpt from the first page of Chapter 2.\n",
        "\n",
        "---\n",
        "\n",
        "Artificial intelligence (AI) embeds in our society, and biases in AI systems will adversely affect your quality of life. These AI systems, particularly in deep learning (DL) and generative AI, depend on the input data you are using to extend data augmentation.\n",
        "\n",
        "AI systems rely heavily on data to make decisions, and if the data used to train the system is biased, then the AI system will make unfair decisions. It will lead to the unjust treatment of individuals or groups and perpetuate systemic inequalities. AI plays a decisive role in life-changing decisions, such as how much your monthly mortgage insurance rate is, whether you can be approved for a car loan, your application qualification for a job, who will receive government assistance, how much you pay for milk, what you read on social media newsfeeds, and how much oil your country will import or export, to name a few.\n",
        "\n",
        "By learning data biases before diving deep into learning data augmentation, you will help develop ethical and fair AI systems that benefit society. It will help you make informed decisions about the data they use and prevent the perpetuation of existing biases and inequalities. Additionally, understanding data bias will help you make informed decisions about the data collection process and ensure itâ€™s representative and unbiased.\n",
        "\n",
        "Data biases may be problematic for data scientists and college students because they are seldom discussed or unavailable in college courses. There is no ready-made fairness matrix to follow programmatically for data augmentation. Maybe by using the latest generative AI, the biases can be done by computer and not heavily rely on humans.\n",
        "\n",
        "There are many strategies to provide protected and safe software products and services, but the AI system requires new processes and perspectives. Trustworthy and responsible AI is about fairness, ethical design, and minimizing biases. Achieving trustworthy AI starts with transparency, datasets, test, evaluation, validation, and verification (TEVV), as defined by the Standard for Identifying and Managing Bias in Artificial Intelligence, National Institute of Standards and Technology (NIST) special publication 1270.\n",
        "\n",
        "---\n",
        "Fun fact\n",
        "\n",
        "---\n",
        "\n",
        "In 2016, Twitter corrupted the Microsoft AI chatbot Tay in 1 day. Microsoft created Tay for online casual and playful conversation. Tay was designed to learn and take input from raw, uncurated data and comments from the web. The Twitter community thought it would be fun to teach Tay with misogynistic, racist, and violent tweets. To this day, Tay is a poster child for lessons learned in data bias input for AI. As one blogger put it, â€œFlaming garbage pile in, flaming garbage pile out.â€\n",
        "\n",
        "---\n",
        "\n",
        "This chapter will provide a crash course on recognizing the differences in computation, human, and systemic biases. We will learn about bias but not practice how to compute bias programmatically. The fairness and confusion matrixes are used to gauge AIâ€™s prediction in terms of true-positive, false-positive, true-negative, and false-negative. However, the fairness and confusion matrixes are used for building AI systems, not data augmentation. While looking at real-world text datasets, we will attempt to write Python code for a fairness matrix with word counts and misspelled words, but for the most part, we will rely on Pluto and your observations to name the biases in image and text data.\n",
        "\n",
        "The Python code in this chapter will focus on helping you learn how to download real-world datasets from the Kaggle website. The later chapters will reuse the helper and wrapper functions shown in this chapter.\n",
        "\n",
        "By the end of this chapter, you will have a deeper appreciation for a balanced dataset. In particular, we will cover the following topics:\n",
        "\n",
        "- Computational biases\n",
        "\n",
        "- Human biases\n",
        "\n",
        "- Systemic biases\n",
        "\n",
        "- Python Notebook\n",
        "\n",
        "- Image biases\n",
        "\n",
        "- Text biases\n",
        "\n",
        "Pluto will begin with the easier of the three biases â€“ computational biases.\n",
        "\n",
        "---\n",
        "\n",
        "ðŸŒ´ *end of excerpt from the book*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psur6TottXJs"
      },
      "source": [
        "# GitHub Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e-E23OC33r_"
      },
      "outputs": [],
      "source": [
        "# git version should be 2.17.1 or higher\n",
        "!git --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk-kUBgEnYzg"
      },
      "outputs": [],
      "source": [
        "url = 'https://github.com/PacktPublishing/Data-Augmentation-with-Python'\n",
        "!git clone {url}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktmuZO3xteG1"
      },
      "source": [
        "## (Optional) Fetch file from URL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGPwtc1p9zQu"
      },
      "source": [
        "- Uncommend the below 2 code cells if you want to use URL and not Git Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oObUsdZcj3Hk"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# #\n",
        "# def fetch_file(url, dst):\n",
        "#   downloaded_obj = requests.get(url)\n",
        "#   with open(dst, \"wb\") as file:\n",
        "#     file.write(downloaded_obj.content)\n",
        "#   return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nrz6ykdEj3RT"
      },
      "outputs": [],
      "source": [
        "# url = ''\n",
        "# dst = 'pluto_chapter_1.py'\n",
        "# fetch_file(url,dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuljFGYftoyb"
      },
      "source": [
        "# Run Pluto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDqYkFLYgSGV"
      },
      "outputs": [],
      "source": [
        "#load and run the pluto chapter 1 Python code.\n",
        "pluto_file = 'Data-Augmentation-with-Python/pluto/pluto_chapter_1.py'\n",
        "%run {pluto_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqZKpMYA3YO1"
      },
      "source": [
        "# Verify Pluto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFMl76ungbF7"
      },
      "outputs": [],
      "source": [
        "pluto.say_sys_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jrAWhOY92ik"
      },
      "source": [
        "- (Optional) Copy the Pluto chapter 1 to begin chapter 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0FKopIH-LZS"
      },
      "outputs": [],
      "source": [
        "pluto_chapter_2 = 'Data-Augmentation-with-Python/pluto/pluto_chapter_2.py'\n",
        "!cp {pluto_file} {pluto_chapter_2}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9azxfCb7tu4"
      },
      "source": [
        "# âœ‹ Get Kaggle ID, key, and setup\n",
        "\n",
        "âœ‹ STOP\n",
        "\n",
        "1. First, sign up on kaggle.com. Get username and api key (refer to the book, Chapter 2)\n",
        "\n",
        "2. Second, You MUST join the State Farm Distracted Driver Competition on the Kaggle website to download the data.\n",
        "  - Go to: https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/overview and click on the \"Join Competition\" button"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrIk0IyLjubl"
      },
      "outputs": [],
      "source": [
        "# %%CARRY-OVER install\n",
        "\n",
        "# easy method to download kaggle data files\n",
        "!pip install opendatasets --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA9BmaTrAhjB"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "pluto.version = 2.0\n",
        "import opendatasets\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def remember_kaggle_access_keys(self,username,key):\n",
        "  self.kaggle_username = username\n",
        "  self.kaggle_key = key\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLI0Yku39gzm"
      },
      "outputs": [],
      "source": [
        "print(\"\\nrequired version 0.1.22 or higher: \", opendatasets.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlzyUNdHfJF_"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _write_kaggle_credit(self):\n",
        "  creds = '{\"username\":\"'+self.kaggle_username+'\",\"key\":\"'+self.kaggle_key+'\"}'\n",
        "  kdirs = [\"~/.kaggle/kaggle.json\", \"./kaggle.json\"]\n",
        "  #\n",
        "  for k in kdirs:\n",
        "    cred_path = pathlib.Path(k).expanduser()\n",
        "    cred_path.parent.mkdir(exist_ok=True)\n",
        "    cred_path.write_text(creds)\n",
        "    cred_path.chmod(0o600)\n",
        "  import kaggle\n",
        "  #\n",
        "  return\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_comp_data(self,cname):\n",
        "  #self._write_kaggle_credit()  # need to run only once.\n",
        "  path = pathlib.Path(cname)\n",
        "  kaggle.api.competition_download_cli(str(path))\n",
        "  zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
        "  return\n",
        "#\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_dataset(self,url,dest=\"kaggle\"):\n",
        "  #self._write_kaggle_credit()    # need to run only once.\n",
        "  opendatasets.download(url,data_dir=dest)\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o44jBb0J96Ae"
      },
      "source": [
        "âœ‹ STOP\n",
        "\n",
        "- user (your_kaggle_username) and (your_kaggle_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzdhZW3qTTr7"
      },
      "outputs": [],
      "source": [
        "# %%CARRY-OVER code\n",
        "\n",
        "pluto.remember_kaggle_access_keys(\"YOR_KAGGLE_KEY\", \"YOUR_KAGGLE_API_KEY\")\n",
        "\n",
        "pluto._write_kaggle_credit()\n",
        "import kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmuApvJnHbNu"
      },
      "source": [
        "# Fetch State Farm real-world dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlsPtSrcD1m2"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msyHmKjHHBx8"
      },
      "source": [
        "âœ‹ STOP\n",
        "\n",
        "- You must join the State Farm Kaggle competition to download the data.\n",
        "\n",
        "- Go to: https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/overview and click on the \"Join Competition\" button"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjQn8Y-FAUMs"
      },
      "outputs": [],
      "source": [
        "kaggle_competition_name = \"state-farm-distracted-driver-detection\"\n",
        "pluto.fetch_kaggle_comp_data(kaggle_competition_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkNc5RNH-k7L"
      },
      "source": [
        "## Quick view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4brCy6pHgBU"
      },
      "outputs": [],
      "source": [
        "# quick view one image\n",
        "f = 'state-farm-distracted-driver-detection/imgs/train/c0/img_100026.jpg'\n",
        "img = PIL.Image.open(f)\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFwEBM-owqDU"
      },
      "source": [
        "# Import to Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbz6nKN8SaqS"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_df(self, csv,sep=','):\n",
        "  df = pandas.read_csv(csv, encoding='latin-1', sep=sep)\n",
        "  return df\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def _fetch_larger_font(self):\n",
        "  heading_properties = [('font-size', '20px')]\n",
        "  cell_properties = [('font-size', '18px')]\n",
        "  dfstyle = [dict(selector=\"th\", props=heading_properties),\n",
        "    dict(selector=\"td\", props=cell_properties)]\n",
        "  return dfstyle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4PtPK9yAUTO"
      },
      "outputs": [],
      "source": [
        "f = 'state-farm-distracted-driver-detection/driver_imgs_list.csv'\n",
        "pluto.df_sf_data = pluto.fetch_df(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCQBHimuG7y3"
      },
      "outputs": [],
      "source": [
        "# pluto.df_sf_data.tail(3)\n",
        "# larger fonts\n",
        "pluto.df_sf_data.tail(3).style.set_table_styles(pluto._fetch_larger_font())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7eS4Svou-fJ"
      },
      "outputs": [],
      "source": [
        "pluto.df_sf_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fds6nk64Q78Y"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def build_sf_fname(self, df):\n",
        "  root = 'state-farm-distracted-driver-detection/imgs/train/'\n",
        "  df[\"fname\"] = root + df.classname+'/'+df.img\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNwTrfCGSPfz"
      },
      "outputs": [],
      "source": [
        "pluto.build_sf_fname(pluto.df_sf_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WJhKFR2JaTF"
      },
      "outputs": [],
      "source": [
        "# pluto.df_sf_data.head(3)\n",
        "# use larger font\n",
        "pluto.df_sf_data.head(3).style.set_table_styles(pluto._fetch_larger_font())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5StcAzNE-W_"
      },
      "source": [
        "- Verify the fname is correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2oKH7i3u-h9"
      },
      "outputs": [],
      "source": [
        "img = PIL.Image.open(pluto.df_sf_data.fname[0])\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPJDMqrwHhCR"
      },
      "source": [
        "# Draw or Display the Photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24Ow2g2SAUP8"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "# set internal counter for image to be zero, e.g. pluto0.jpg, pluto1.jpg, etc.\n",
        "pluto.fname_id = 0\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def _drop_image(self,canvas, fname=None,format=\".jpg\",dname=\"Data-Augmentation-with-Python/pluto_img\"):\n",
        "  if (fname is None):\n",
        "    self.fname_id += 1\n",
        "    if not os.path.exists(dname):\n",
        "      os.makedirs(dname)\n",
        "    fn = f'{dname}/pluto{self.fname_id}{format}'\n",
        "  else:\n",
        "    fn = fname\n",
        "  canvas.savefig(fn, bbox_inches=\"tight\", pad_inches=0.25)\n",
        "  return\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def draw_batch(self,df_filenames, disp_max=10,is_shuffle=False, figsize=(16,8)):\n",
        "  disp_col = 5\n",
        "  disp_row = int(numpy.round((disp_max/disp_col)+0.4, 0))\n",
        "  _fns = list(df_filenames)\n",
        "  if (is_shuffle):\n",
        "    numpy.random.shuffle(_fns)\n",
        "  k = 0\n",
        "  clean_fns = []\n",
        "  if (len(_fns) >= disp_max):\n",
        "    canvas, pic = matplotlib.pyplot.subplots(disp_row,disp_col, figsize=figsize)\n",
        "    for i in range(disp_row):\n",
        "      for j in range(disp_col):\n",
        "        try:\n",
        "          im = PIL.Image.open(_fns[k])\n",
        "          pic[i][j].imshow(im)\n",
        "          pic[i][j].set_title(pathlib.Path(_fns[k]).name)\n",
        "          clean_fns.append(_fns[k])\n",
        "        except:\n",
        "          pic[i][j].set_title(pathlib.Path(_fns[k]).name)\n",
        "        k += 1\n",
        "    canvas.tight_layout()\n",
        "    self._drop_image(canvas)\n",
        "    canvas.show()\n",
        "  else:\n",
        "    print(\"**Warning: the length should be more then \", disp_max, \". The given length: \", len(_fns))\n",
        "  return clean_fns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLpFNMbhosse"
      },
      "source": [
        "## State Farm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBHg630AQ7-4"
      },
      "outputs": [],
      "source": [
        "x = pluto.draw_batch(pluto.df_sf_data[\"fname\"], is_shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDRAN9CMUPu_"
      },
      "outputs": [],
      "source": [
        "x = pluto.draw_batch(pluto.df_sf_data[\"fname\"], is_shuffle=True,disp_max=20,figsize=(18,14))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC6194qMFkjI"
      },
      "source": [
        "## Nike Shoe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-twSheiJDcqw"
      },
      "source": [
        "- For Nike, Adidas and Converse Shoes Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "976ioIMEDb14"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.kaggle.com/datasets/die9origephit/nike-adidas-and-converse-imaged'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YepsITDBCDO"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def build_shoe_fname(self, start_path):\n",
        "  df = pandas.DataFrame()\n",
        "  for root, dirs, files in os.walk(start_path, topdown=False):\n",
        "   for name in files:\n",
        "      f = os.path.join(root, name)\n",
        "      p = pathlib.Path(f).parent.name \n",
        "      d = pandas.DataFrame({'fname': [f], 'label': [p]})\n",
        "      df = pandas.concat([df, d], ignore_index=True)\n",
        "      #df = df.append(d, ignore_index=True)\n",
        "  #\n",
        "  # clean it up\n",
        "  df = df.reset_index(drop=True)\n",
        "  return df\n",
        "#\n",
        "# create the same with a generic function name\n",
        "@add_method(PacktDataAug)\n",
        "def make_dir_dataframe(self, start_path):\n",
        "  return self.build_shoe_fname(start_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZd9PK8qBCGV"
      },
      "outputs": [],
      "source": [
        "f = 'kaggle/nike-adidas-and-converse-imaged/train'\n",
        "pluto.df_shoe_data = pluto.build_shoe_fname(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6yQ9foxNQeU"
      },
      "outputs": [],
      "source": [
        "# pluto.df_shoe_data.head(3)\n",
        "# use larger font\n",
        "pluto.df_shoe_data.head(3).style.set_table_styles(pluto._fetch_larger_font())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POnMlbypF6w6"
      },
      "outputs": [],
      "source": [
        "pluto.df_shoe_data.tail(3).style.set_table_styles(pluto._fetch_larger_font())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5laIx-5CKHci"
      },
      "outputs": [],
      "source": [
        "x = pluto.draw_batch(pluto.df_shoe_data[\"fname\"], is_shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GttGBLD7KHgH"
      },
      "outputs": [],
      "source": [
        "x = pluto.draw_batch(pluto.df_shoe_data[\"fname\"], is_shuffle=True,disp_max=20,figsize=(18,14))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5yepxXNXP1j"
      },
      "source": [
        "## Grapevine Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-d5upIYAUGQ"
      },
      "outputs": [],
      "source": [
        "#\n",
        "%%time\n",
        "url = \"https://www.kaggle.com/datasets/muratkokludataset/grapevine-leaves-image-dataset\"\n",
        "pluto.fetch_kaggle_dataset(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdUXalz5B9YS"
      },
      "outputs": [],
      "source": [
        "!ls -la kaggle/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FThHU_5ADbzJ"
      },
      "outputs": [],
      "source": [
        "f = 'kaggle/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset/Ak'\n",
        "!ls -la {f} | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPZl5lLPDtGk"
      },
      "source": [
        "- remove all space in file name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZix-nbeDb2q"
      },
      "outputs": [],
      "source": [
        "# run this until no error/output\n",
        "f2 = 'kaggle/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset'\n",
        "!find {f2} -name \"* *\" -type f | rename 's/ /_/g'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUBs0dnpEWo5"
      },
      "outputs": [],
      "source": [
        "!ls -la {f} | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJQS_NbQEWr_"
      },
      "outputs": [],
      "source": [
        "f = 'kaggle/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset/Grapevine_Leaves_Image_Dataset_Citation_Request.txt'\n",
        "!cat {f}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGO0X1OdEWvL"
      },
      "outputs": [],
      "source": [
        "!mv {f} ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoV6Y9fiHyEQ"
      },
      "source": [
        "- The grapevine image structure is the same as the shoe image.\n",
        "  - folder name is the label\n",
        "  - the images are in their respected folder\n",
        "  - No csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mu6R0JvDIyRQ"
      },
      "outputs": [],
      "source": [
        "f = 'kaggle/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset'\n",
        "pluto.df_grapevine_data = pluto.build_shoe_fname(f)\n",
        "pluto.df_grapevine_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iy0Mqw4IyUk"
      },
      "outputs": [],
      "source": [
        "x = pluto.draw_batch(pluto.df_grapevine_data[\"fname\"], is_shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bESehTZcIyYd"
      },
      "outputs": [],
      "source": [
        "x = pluto.draw_batch(pluto.df_grapevine_data[\"fname\"], is_shuffle=True,disp_max=20,figsize=(18,14))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8RpBwppEPjJ"
      },
      "source": [
        "## Monkeypox (optional for Notebook only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivVgADDcSwNc"
      },
      "source": [
        "- Uncoment before run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzukIrKQRJP-"
      },
      "outputs": [],
      "source": [
        "# # quick view one image\n",
        "# f = 'kaggle/monkeypox-skin-lesion-dataset/Original Images/Original Images/Monkey Pox/M01_03.jpg'\n",
        "# img = PIL.Image.open(f)\n",
        "# display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8T7j5fQR10j"
      },
      "outputs": [],
      "source": [
        "# f = 'kaggle/monkeypox-skin-lesion-dataset/Augmented Images/Augmented Images/Monkeypox_augmented/M01_01_02.jpg'\n",
        "# img = PIL.Image.open(f)\n",
        "# display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zF8CDztXOpq"
      },
      "outputs": [],
      "source": [
        "# f = 'kaggle/monkeypox-skin-lesion-dataset/Monkeypox_Dataset_metadata.csv'\n",
        "# pluto.df_monkey_data = pluto.fetch_df(f)\n",
        "# pluto.df_monkey_data.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VW1NkFIaKeZ"
      },
      "source": [
        "- Run this until No error\n",
        "- 3 times for monkeypox "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94zilgGnUP4U"
      },
      "outputs": [],
      "source": [
        "# !find . -name \"* *\" -type d | rename 's/ /_/g'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvj_VTTTUP1l"
      },
      "outputs": [],
      "source": [
        "# # %write -a {pluto_chapter_2}\n",
        "\n",
        "# @add_method(PacktDataAug)\n",
        "# def build_monkey_fname(self, df):\n",
        "#   url_monkey = 'kaggle/monkeypox-skin-lesion-dataset/Original_Images/Original_Images/Monkey_Pox/'\n",
        "#   url_other = 'kaggle/monkeypox-skin-lesion-dataset/Original_Images/Original_Images/Others/'\n",
        "#   df[\"fname\"] = url_monkey + df.ImageID + \".jpg\"\n",
        "#   # quick replace other\n",
        "#   df.loc[df['Label'] == 'Non Monkeypox', 'fname'] = url_other + df.ImageID + \".jpg\"\n",
        "#   return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SzJwXD8-4Vc"
      },
      "outputs": [],
      "source": [
        "# pluto.build_monkey_fname(pluto.df_monkey_data)\n",
        "# pluto.df_monkey_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1vUEyMk_HlV"
      },
      "outputs": [],
      "source": [
        "# pluto.df_monkey_data.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSHn4pBvBDd6"
      },
      "source": [
        "- Draw it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzPx3_93BCAY"
      },
      "outputs": [],
      "source": [
        "# x = pluto.draw_batch(pluto.df_monkey_data[\"fname\"], is_shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhLRWfp8FfZh"
      },
      "outputs": [],
      "source": [
        "# x = pluto.draw_batch(pluto.df_monkey_data[\"fname\"], is_shuffle=True,disp_max=20,figsize=(18,14))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-VcqVraHmUD"
      },
      "source": [
        "# NLP (Text) data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62oZJxvUv14r"
      },
      "source": [
        "## NetFlix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxTEQAe3NLk_"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "url = 'https://www.kaggle.com/datasets/infamouscoder/dataset-netflix-shows'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dULyUTA5NLv5"
      },
      "outputs": [],
      "source": [
        "f = 'kaggle/dataset-netflix-shows/netflix_titles.csv'\n",
        "pluto.df_netflix_data = pluto.fetch_df(f)\n",
        "#pluto.df_netflix_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1AqoWw8W9WL"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_batch_text(self,df_orig, disp_max=6, cols=[\"title\", \"description\"],is_larger_font=True): \n",
        "  df = df_orig[cols] \n",
        "  with pandas.option_context(\"display.max_colwidth\", None):\n",
        "    if (is_larger_font):\n",
        "      display(df.sample(disp_max).style.set_table_styles(self._fetch_larger_font()))\n",
        "    else:\n",
        "      display(df.sample(disp_max))\n",
        "  return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAAtoTx7ET5V"
      },
      "source": [
        "- Show table in three part for book  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuPQ1xbNFH5G"
      },
      "outputs": [],
      "source": [
        "pluto.print_batch_text(pluto.df_netflix_data.head(3),\n",
        "  disp_max=3,\n",
        "  cols=['show_id', 'type','title','director','cast'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IU9lhl4FkV8"
      },
      "outputs": [],
      "source": [
        "pluto.print_batch_text(pluto.df_netflix_data.head(3),\n",
        "  disp_max=3,\n",
        "  cols=['country', 'date_added','release_year','rating'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4b4QdarO0ba"
      },
      "outputs": [],
      "source": [
        "#pluto.df_netflix_data.head(3)[['duration', 'listed_in','description']].style.set_table_styles(pluto._fetch_larger_font())\n",
        "pluto.print_batch_text(pluto.df_netflix_data.head(3),\n",
        "  disp_max=3,\n",
        "  cols=['duration', 'listed_in','description'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yMBi-uKNLzU"
      },
      "outputs": [],
      "source": [
        "#print(pluto.df_netflix_data.description[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52RkujJwu8cV"
      },
      "outputs": [],
      "source": [
        "pluto.print_batch_text(pluto.df_netflix_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAvOL1kSZ57w"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def count_word(self, df, col_dest=\"description\"):\n",
        "  df['wordc'] = df[col_dest].apply(lambda x: len(x.split()))\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmSKV0gQZ6mn"
      },
      "outputs": [],
      "source": [
        "pluto.count_word(pluto.df_netflix_data)\n",
        "# pluto.df_netflix_data.head()\n",
        "pluto.print_batch_text(pluto.df_netflix_data,cols=['description','wordc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acjTlcQSdV8b"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def draw_word_count(self,df, wc='wordc',is_stack_verticle=True):\n",
        "  if (is_stack_verticle):\n",
        "    canvas, pic = matplotlib.pyplot.subplots(2,1, figsize=(8,10))\n",
        "  else:\n",
        "    canvas, pic = matplotlib.pyplot.subplots(1,2, figsize=(16,5))\n",
        "  df.boxplot(ax=pic[0],column=[wc],vert=False,color=\"black\")\n",
        "  df[wc].hist(ax=pic[1], color=\"cornflowerblue\", alpha=0.9)\n",
        "  #\n",
        "  title=[\"Description BoxPlot\", \"Description Histogram\"]\n",
        "  yaxis=[\"Description\", \"Stack\"]\n",
        "  x1 = f'Word Count: Mean: {df[wc].mean():0.2f}, Min: {df[wc].min()}, Max: {df[wc].max()}'\n",
        "  xaxis=[x1, \"Word Count\"]\n",
        "  #\n",
        "  pic[0].set_title(title[0], fontweight =\"bold\")\n",
        "  pic[1].set_title(title[1], fontweight =\"bold\")\n",
        "  pic[0].set_ylabel(yaxis[0])\n",
        "  pic[1].set_ylabel(yaxis[1])\n",
        "  pic[0].set_xlabel(xaxis[0])\n",
        "  pic[1].set_xlabel(xaxis[1])\n",
        "  #\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  # \n",
        "  canvas.show()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT6sgrOggfmJ"
      },
      "outputs": [],
      "source": [
        "pluto.draw_word_count(pluto.df_netflix_data, is_stack_verticle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXJLBhwdtbGl"
      },
      "outputs": [],
      "source": [
        "pluto.draw_word_count(pluto.df_netflix_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se_OcR7cWc8p"
      },
      "source": [
        "## Spell checker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCygEQbLWbj6"
      },
      "outputs": [],
      "source": [
        "# %%CARRY-OVER code install\n",
        "\n",
        "!pip install pyspellchecker "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D-0hhx0WbnA"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_2}\n",
        "\n",
        "import re\n",
        "import spellchecker\n",
        "@add_method(PacktDataAug)\n",
        "def _strip_punc(self,s):\n",
        "  p = re.sub(r'[^\\w\\s]','',s)\n",
        "  return(p)\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def check_spelling(self,df, col_dest='description'):\n",
        "  spell = spellchecker.SpellChecker()\n",
        "  df[\"misspelled\"] = df[col_dest].apply(lambda x: spell.unknown(self._strip_punc(x).split()))\n",
        "  df[\"misspelled_count\"] = df[\"misspelled\"].apply(lambda x: len(x))\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kEGGHiHG7Xu"
      },
      "outputs": [],
      "source": [
        "pluto._pp(\"Required version 0.7+\", spellchecker.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stTJxEYWWbqT"
      },
      "outputs": [],
      "source": [
        "pluto.check_spelling(pluto.df_netflix_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnplTCzBbJHU"
      },
      "outputs": [],
      "source": [
        "pluto.print_batch_text(pluto.df_netflix_data,cols=['description', 'misspelled'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4XDpkifbJKi"
      },
      "outputs": [],
      "source": [
        "pluto.draw_word_count(pluto.df_netflix_data,wc='misspelled_count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTrkXuUUX8bS"
      },
      "source": [
        "## Amazon review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqcBOQJSX7XG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "url = 'https://www.kaggle.com/datasets/tarkkaanko/amazon'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qze-n7Q6X7aS"
      },
      "outputs": [],
      "source": [
        "f = 'kaggle/amazon/amazon_reviews.csv'\n",
        "pluto.df_amazon_data = pluto.fetch_df(f)\n",
        "pluto.df_amazon_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHPoeB93HAER"
      },
      "outputs": [],
      "source": [
        "# there is a \"nan\" in the amazon data, so drop/delete it.\n",
        "pluto.df_amazon_data = pluto.df_amazon_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eB6OwxXmdvQb"
      },
      "outputs": [],
      "source": [
        "pluto.check_spelling(pluto.df_amazon_data,col_dest='reviewText')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkZewkTTX7d_"
      },
      "outputs": [],
      "source": [
        "pluto.print_batch_text(pluto.df_amazon_data, cols=['reviewText','misspelled'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKzQYshSX7kN"
      },
      "outputs": [],
      "source": [
        "pluto.count_word(pluto.df_amazon_data,col_dest='reviewText')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNA2t2UdHfGc"
      },
      "outputs": [],
      "source": [
        "pluto.draw_word_count(pluto.df_amazon_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOIXZwOkedAU"
      },
      "outputs": [],
      "source": [
        "pluto.draw_word_count(pluto.df_amazon_data, wc='misspelled_count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1EShKkLVpWL"
      },
      "outputs": [],
      "source": [
        "# end of chapter 2\n",
        "print('End of chapter 2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEj7fgaIN9_S"
      },
      "source": [
        "# Push up all changes (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHXRf21BT9N8"
      },
      "source": [
        "- username: [use your name or email]\n",
        "\n",
        "- password: [use the token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSXJKJFlOEeE"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# f = 'Data-Augmentation-with-Python'\n",
        "# os.chdir(f)\n",
        "# !git add -A\n",
        "# !git config --global user.email \"duc.haba@gmail.com\"\n",
        "# !git config --global user.name \"duchaba\"\n",
        "# !git commit -m \"end of session\"\n",
        "# #do the git push in the xterm console\n",
        "# #!git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzO7lDYDWeLz"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2iUPf3EWePd"
      },
      "source": [
        "Every chaper will begin with same base class \"PacktDataAug\".\n",
        "\n",
        "âœ‹ FAIR WARNING:\n",
        "\n",
        "- The coding uses long and complete function path name.\n",
        "\n",
        "- I wrote the code for easy to understand and not for compactness, fast execution, nor cleaverness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXRG3KaeWbGx"
      },
      "outputs": [],
      "source": [
        "# !pip install colab-xterm\n",
        "# %load_ext colabxterm\n",
        "# %xterm"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMKvpxiMyAgoI2S17vYEgTx",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}